{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# (Optional) Practice Assignment: Clustering\n",
    "\n",
    "In this practice assignment, you will explore the K-Means and Agglomerative Clustering algorithms. This assignment is purely for you to practice clustering and will **not** be graded!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "from sklearn import cluster\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Example\n",
    "\n",
    "Let us begin with a toy dataset with three groups that are completely separated from each other. The three groups are generated with the same number of points per group and the same variance within each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n",
    "\n",
    "c1 = np.random.randn(25, 2)\n",
    "c2 = np.array([2, 8]) + np.random.randn(25, 2)\n",
    "c3 = np.array([8, 4]) + np.random.randn(25, 2)\n",
    "\n",
    "x1 = np.vstack((c1, c2, c3))\n",
    "\n",
    "sns.scatterplot(x=x1[:, 0], y=x1[:, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the K-Means algorithm, we can see that it is able to accurately pick out the three clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmeans = cluster.KMeans(n_clusters=3, random_state=42).fit(x1)\n",
    "sns.scatterplot(x=x1[:, 0], y=x1[:, 1], hue=kmeans.labels_)\n",
    "sns.scatterplot(x=kmeans.cluster_centers_[:, 0], y=kmeans.cluster_centers_[:, 1], color='blue', marker='x', s=300, linewidth=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 1\n",
    "\n",
    "In the previous example, the K-Means algorithm was able to accurately find the three clusters. However, changing the starting centers for K-Means can change the final clusters that K-Means gives us. Change the initial centers to the points `[0, 1]`, `[1, 1]`, and `[2, 2]`; then fit a [`cluster.KMeans`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) object called `kmeans_q1` on the toy dataset from the previous example. Keep the `random_state` parameter as 42 and the `n_clusters` parameter as 3.\n",
    "\n",
    "**Hint:** You will need to change the `init` and `n_init` parameters in `cluster.KMeans`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_q1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the K-Means algorithm with these initial centers gives us a different result from before, and this particular run of K-Means was unable to accurately identify the three clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=x1[:, 0], y=x1[:, 1], hue=kmeans_q1.labels_)\n",
    "sns.scatterplot(x=kmeans_q1.cluster_centers_[:, 0], y=kmeans_q1.cluster_centers_[:, 1], color='blue', marker='x', s=300, linewidth=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Sometimes, K-Means will have a difficult time finding the \"correct\" clusters even with ideal starting centers. For example, consider the data below. The smaller group has smaller variability and is less numerous, and the larger group is more spread out and populated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n",
    "\n",
    "c1 = 0.5 * np.random.randn(25, 2)\n",
    "c2 = np.array([10, 10]) + 3*np.random.randn(475, 2)\n",
    "\n",
    "x2 = np.vstack((c1, c2))\n",
    "\n",
    "sns.scatterplot(x=x2[:, 0], y=x2[:, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2a\n",
    "\n",
    "Fit a `cluster.KMeans` object called `kmeans_q2a` on the dataset above with two clusters and a `random_state` parameter of 42.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_q2a = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(For notational simplicity we will call the cluster on the bottom left $A$ and the cluster on the top right $B$. We will call the bottom left cluster found by K-Means as cluster $a$ and the top right cluster found by K-Means as cluster $b$.) \n",
    "\n",
    "As seen below, K-Means is unable to find the two intial clusters because cluster $a$ includes points from cluster $B$. Recall that K-Means attempts to minimize distortion, so it makes sense that points in the bottom left of cluster $B$ would prefer to be in cluster $a$ rather than cluster $b$. If these points were in cluster $b$ instead, then the resulting cluster assignments would have a larger distortion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=x2[:, 0], y=x2[:, 1], hue=kmeans_q2a.labels_)\n",
    "sns.scatterplot(x=kmeans_q2a.cluster_centers_[:, 0], y=kmeans_q2a.cluster_centers_[:, 1], color='red', marker='x', s=300, linewidth=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2b\n",
    "\n",
    "It turns out agglomerative clustering works better for this task, as long as we choose the right definition of distance between two clusters. Recall that agglomerative clustering starts with every data point in its own cluster and iteratively joins the two closest clusters until there are $K$ clusters remaining. However, the \"distance\" between two clusters is ambiguous. \n",
    "\n",
    "In lecture 23 we used the maximum distance between a point in the first cluster and a point in the second as this notion of distance, but there are other ways to define the distance between two clusters. \n",
    "\n",
    "Our choice of definition for the distance is sometimes called the \"linkage criterion.\" We will discuss three linkage criteria, each of which is a different definition of \"distance\" between two clusters:\n",
    "\n",
    "- **Complete** linkage considers the distance between two clusters as the **maximum** distance between a point in the first cluster and a point in the second. This is what we did in [lecture 23](https://docs.google.com/presentation/d/19TdgyT7vnnz6mR0-yftJH6iVpplQeTnohobvAr0dOeY/edit#slide=id.g8e2e3a4c90_0_1144).\n",
    "- **Single** linkage considers the distance between two clusters as the **minimum** distance between a point in the first cluster and a point in the second.\n",
    "- **Average** linkage considers the distance between two clusters as the **average** distance between a point in the first cluster and a point in the second.\n",
    "\n",
    "Using the **complete linkage criterion**, fit a [`cluster.AgglomerativeClustering`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html) object called `aggc_q2b` on the dataset above with two clusters.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggc_q2b = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we visualize the results of your model. Note that complete linkage agglomerative clustering has the same issue as K-Means in that the bottom left cluster found by complete linkage agglomerative clustering includes points from the top right cluster. However, we can remedy this by picking a different linkage criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=x2[:, 0], y=x2[:, 1], hue=aggc_q2b.labels_);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2c\n",
    "\n",
    "Now, use the single linkage criterion to fit a `cluster.AgglomerativeClustering` object called `aggc_q2c` on the dataset above with two clusters.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2c\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggc_q2c = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we see that single linkage agglomerative clustering is able to find the two clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=x2[:, 0], y=x2[:, 1], hue=aggc_q2c.labels_);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does single linkage accurately identify the two clusters while complete linkage fails?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "For this question, consider the following toy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n",
    "\n",
    "c1 = np.random.multivariate_normal([-3,0], [[.5,0],[0,4]], 100)\n",
    "c2 = np.random.multivariate_normal([3,0], [[.5,0],[0,4]], 100)\n",
    "c3 = np.random.multivariate_normal([0,6], [[4,0],[0,.5]], 100)\n",
    "x3 = np.vstack((c1, c2, c3))\n",
    "\n",
    "sns.scatterplot(x=x3[:, 0], y=x3[:, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3a\n",
    "\n",
    "Fit three different `cluster.KMeans` objects on the dataset above called `kmeans_q32`, `kmeans_q33`, and `kmeans_q34`. These three objects should be fit with two, three, and four clusters respectively. Use a `random_state` parameter of 42.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_q32 = ...\n",
    "kmeans_q33 = ...\n",
    "kmeans_q34 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=x3[:, 0], y=x3[:, 1], hue=kmeans_q32.labels_)\n",
    "sns.scatterplot(x=kmeans_q32.cluster_centers_[:, 0], y=kmeans_q32.cluster_centers_[:, 1], color='blue', marker='x', s=300, linewidth=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=x3[:, 0], y=x3[:, 1], hue=kmeans_q33.labels_)\n",
    "sns.scatterplot(x=kmeans_q33.cluster_centers_[:, 0], y=kmeans_q33.cluster_centers_[:, 1], color='blue', marker='x', s=300, linewidth=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=x3[:, 0], y=x3[:, 1], hue=kmeans_q34.labels_)\n",
    "sns.scatterplot(x=kmeans_q34.cluster_centers_[:, 0], y=kmeans_q34.cluster_centers_[:, 1], color='blue', marker='x', s=300, linewidth=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3b\n",
    "\n",
    "Based on the three plots above, how many clusters do you think we should use? Assign your answer to the variable `k_q3b`.\n",
    "\n",
    "**Note:** We will accept any of the three possible answers here, but one of the three plots might be more visually appealing than the other two.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_q3b = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3c\n",
    "\n",
    "We can also use silhouette plots to select the number of clusters $K$. The following code is borrowed from https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = x3\n",
    "\n",
    "range_n_clusters = [2, 3, 4]\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = cluster.KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
    "                c=colors, edgecolor='k')\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = clusterer.cluster_centers_\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                    s=50, edgecolor='k')\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Suppose we want to pick the number of clusters based on the highest average silhouette score. Given the silhouette plots above, how many clusters should we use? Assign your answer to the variable `k_q3c`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3c\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_q3c = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "In the previous three questions, we looked at clustering on two dimensional datasets. However, we can easily use clustering on data which have more than two dimensions. For this, let us turn to a World Bank dataset, containing various features for the world's countries.\n",
    "\n",
    "This data comes from https://databank.worldbank.org/source/world-development-indicators#.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_bank_data = pd.read_csv(\"world_bank_data.csv\", index_col = 'country')\n",
    "world_bank_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some missing values. For the sake of convenience and keeping the assignment short, we will fill them all with zeros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_bank_data = world_bank_data.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Using all available features, fit a `cluster.KMeans` object called `kmeans_q4` with four clusters and a `random_state` parameter of 42.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_q4 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the clusters, we see that almost all countries get clustered together, and the other 3 clusters seem to have countries with vaguely similar levels of economic and geopolitcal power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_world_bank_data = world_bank_data.copy()\n",
    "labeled_world_bank_data['cluster'] = kmeans_q4.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(labeled_world_bank_data.query('cluster == 0').index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(labeled_world_bank_data.query('cluster == 1').index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(labeled_world_bank_data.query('cluster == 2').index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(labeled_world_bank_data.query('cluster == 3').index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the meaning of these clusters, we could look at `kmeans_q4.cluster_centers_`. We leave this as a very challenging exercise for students who are especially interested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Like with PCA, it sometimes makes sense to center and scale our data so that features with higher variance don't dominate the analysis. For example, in the clustering above, statistics like population will completely dominate features like % of total population that live in urban areas. This is because population can range over billions whereas % is always between 0 and 100. The ultimate effect is that we're not really using most of our columns at all.\n",
    "\n",
    "Below, repeat the clustering process from question 4. As before, fit a `cluster.KMeans` object called `kmeans_q5` with four clusters and a `random_state` parameter of 42.\n",
    "\n",
    "The difference is that this time you should use a centered and scaled version of the world bank data. The mean of each column should be 0 and the variance of each column should be 1.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "kmeans_q5 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at these new clusters, we see that they seem to correspond to:\n",
    "\n",
    "0: Very small countries (population).\n",
    "\n",
    "1: Developed countries with a huge population.\n",
    "\n",
    "2: Developing/more developed countries.\n",
    "\n",
    "3: Huge countries (population). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labeled_world_bank_data_q5 = pd.Series(kmeans_q5.labels_, name = \"cluster\", index  = world_bank_data.index).to_frame()\n",
    "labeled_world_bank_data_q5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(labeled_world_bank_data_q5.query('cluster == 0').index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(labeled_world_bank_data_q5.query('cluster == 1').index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(labeled_world_bank_data_q5.query('cluster == 2').index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list(labeled_world_bank_data_q5.query('cluster == 3').index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Please ignore the submission instructions below, this is an optional ungraded practice assignment so there is no required Gradescope submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(\"clustering_practice.ipynb\", pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
