{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Homework 4: Trump, Twitter, and Text\n",
    "\n",
    "## Due Date: Thursday 10/08, 11:59 pm PST\n",
    "\n",
    "Welcome to the fourth homework assignment of Data 100/200! In this assignment, we will work with Twitter data in order to analyze Donald Trump's tweets.\n",
    "\n",
    "**Collaboration Policy**\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the homework, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators**: *list collaborators here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import zipfile\n",
    "\n",
    "# Ensure that Pandas shows at least 280 characters in columns, so we can see full tweets\n",
    "pd.set_option('max_colwidth', 280)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Breakdown\n",
    "\n",
    "Question | Points\n",
    "--- | ---\n",
    "0 | 1\n",
    "1 | 2\n",
    "2 | 1\n",
    "3 | 2\n",
    "4a | 1\n",
    "4b | 2\n",
    "4c | 2\n",
    "4d | 1\n",
    "5a | 1\n",
    "5b | 1\n",
    "5c | 1\n",
    "5d | 1\n",
    "5e | 1\n",
    "5f | 2\n",
    "5g | 2\n",
    "5h | 1\n",
    "6a | 1\n",
    "6b | 1\n",
    "7a | 2\n",
    "7b | 1\n",
    "Total | 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we start ##\n",
    "All data is made from real-world phenomena, be it the movement of the planets, animal behavior, or human bodies and activities. Working with data always has a bearing back on how human beings know and act in the world. The dataset that you're about to work with in this homework consists of a compilation of President Trump's Tweets. It's important to acknowledge that these Tweets are more than just data -- they're the means by which the President expresses his opinions, performs public and foreign policy, and shapes the lives of people in the US and all over the world. More fundamentally, these Tweets are a powerful form of speech that is particularly significant on the eve of the 2020 US Presidential Election. We recognize that working with this data now, even in the context of a technical exercise, is not a neutral activity and may create difficult feelings in students. We encourage you to observe what you may be experiencing and invite you to consider these dimensions of data science work alongside your technical lessons and we're glad to discuss these issues together in section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer about `sns.distplot()`\n",
    "\n",
    "This homework was designed for a slightly older version of seaborn, which does not support the new `displot` method taught in Lecture 9. Instead, in this homework we will heavily rely on `distplot` (with a `t`). As you may have noticed in lab 5, use of the `distplot` function triggers a deprecation warning to notify the user that they should replace all deprecated functions with the updated version. Generally, warnings should not be suppressed but we will do so in this assignment to avoid cluttering.\n",
    "\n",
    "See the seaborn documentation on [distributions](https://seaborn.pydata.org/tutorial/distributions.html) and [functions](https://seaborn.pydata.org/tutorial/function_overview.html) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to suppress all DeprecationWarnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "# Part 1: Importing the Data\n",
    "\n",
    "We will use the `fetch_and_cache` utility to download the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "download-data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "from ds100_utils import fetch_and_cache\n",
    "data_url = 'http://www.ds100.org/fa19/assets/datasets/hw4-realdonaldtrump_tweets.json.zip'\n",
    "file_name = 'hw4-realdonaldtrump_tweets.json.zip'\n",
    "\n",
    "dest_path = fetch_and_cache(data_url=data_url, file=file_name)\n",
    "print(f'Located at {dest_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've downloaded the tweets, let's unzip them and load them into our notebook. Run the cell below to unzip and read tweets from the json file into a list named `all_tweets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the dataset\n",
    "my_zip = zipfile.ZipFile(dest_path, 'r')\n",
    "with my_zip.open('hw4-realdonaldtrump_tweets.json', 'r') as f:\n",
    "    all_tweets = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "formatting-note",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Here is what a typical tweet from `all_tweets` looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "pprint-old-tweets",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint # to get a more easily-readable view.\n",
    "pprint(all_tweets[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Question 0\n",
    "There are many ways we could choose to read the President’s tweets. Why might someone be interested in doing data analysis on the President’s tweets? Name a kind of person or institution which might be interested in this kind of analysis. Then, give two reasons why a data analysis of the President's tweets might be interesting or useful for them. Answer in 2-3 sentences.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q0\n",
    "points: 1\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q3b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Question 1\n",
    "\n",
    "Construct a DataFrame called `trump` containing data from all the tweets stored in `all_tweets`. The index of the DataFrame should be the ID of each tweet (looks something like `907698529606541312`). It should have these columns:\n",
    "\n",
    "- `time`: The time the tweet was created encoded as a datetime object. (Use `pd.to_datetime` to encode the timestamp.)\n",
    "- `source`: The source device of the tweet.\n",
    "- `text`: The text of the tweet.\n",
    "- `retweet_count`: The retweet count of the tweet. \n",
    "\n",
    "Finally, **the resulting DataFrame should be sorted by the index.**\n",
    "\n",
    "**Warning:** *Some tweets will store the text in the `text` field and other will use the `full_text` field.*\n",
    "\n",
    "**Hint: You might want to explicitly specify the columns and indices using** `pd.DataFrame()`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3b-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "scrolled": false,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "trump = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "question4",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "# Part 2: Tweet Source Analysis\n",
    "\n",
    "In the following questions, we are going to find out the charateristics of Trump tweets and the devices used for the tweets.\n",
    "\n",
    "First let's examine the source field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "unique-sources",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "trump['source'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q4a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 2\n",
    "\n",
    "Notice how sources like \"Twitter for Android\" or \"Instagram\" are surrounded by HTML tags. In the cell below, clean up the `source` field by removing the HTML tags from each `source` entry.\n",
    "\n",
    "**Hints:** \n",
    "* Use `trump['source'].str.replace` along with a regular expression.\n",
    "* You may find it helpful to experiment with regular expressions at [regex101.com](https://regex101.com/).\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "## Uncomment and complete\n",
    "# trump['source'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "note-about-device-usage",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "In the following plot, we see that there are two device types that are more commonly used than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "device-usage-plot",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "trump['source'].value_counts().plot(kind=\"bar\")\n",
    "plt.xlabel('Source')\n",
    "plt.ylabel(\"Number of Tweets\")\n",
    "plt.title(\"Number of Tweets by Source\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q5",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 3\n",
    "\n",
    "Now that we have cleaned up the `source` field, let's look at which device Trump has used over the entire time period of this dataset.\n",
    "\n",
    "To examine the distribution of dates we will convert the date to a fractional year that can be plotted as a distribution.\n",
    "\n",
    "(Code borrowed from this [link](https://stackoverflow.com/questions/6451655/python-how-to-convert-datetime-dates-to-decimal-years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "fractional-year",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def year_fraction(date):\n",
    "    start = datetime.date(date.year, 1, 1).toordinal()\n",
    "    year_length = datetime.date(date.year+1, 1, 1).toordinal() - start\n",
    "    return date.year + float(date.toordinal() - start) / year_length\n",
    "\n",
    "trump['year'] = trump['time'].apply(year_fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q5a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Now, use `sns.distplot` to overlay the distributions of Trump's 2 most frequently used web technologies over the years. Your final plot should look similar to the plot below:\n",
    "\n",
    "<img src=\"images/source_years_q3.png\" width=\"600px\" />\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3\n",
    "points: 2\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q5a-answer",
     "locked": false,
     "points": 2,
     "schema_version": 2,
     "solution": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## Question 4\n",
    "\n",
    "\n",
    "Is there a difference between Trump's tweet behavior across these devices? We will attempt to answer this question in our subsequent analysis.\n",
    "\n",
    "First, we'll take a look at whether Trump's tweets from an Android device come at different times than his tweets from an iPhone. Note that Twitter gives us his tweets in the [UTC timezone](https://www.wikiwand.com/en/List_of_UTC_time_offsets) (notice the `+0000` in the first few tweets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "tweet-created-at",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "for tweet in all_tweets[:3]:\n",
    "    print(tweet['created_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "convert-to-est-justification",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "We'll convert the tweet times to US Eastern Time, the timezone of New York and Washington D.C., since those are the places we would expect the most tweet activity from Trump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "convert-to-est",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "trump['est_time'] = (\n",
    "    trump['time'].dt.tz_convert(\"EST\") # Convert to Eastern Time\n",
    ")\n",
    "trump.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "need-to-do",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 4a\n",
    "\n",
    "Add a column called `hour` to the `trump` table which contains the hour of the day as floating point number computed by:\n",
    "\n",
    "$$\n",
    "\\text{hour} + \\frac{\\text{minute}}{60} + \\frac{\\text{second}}{60^2}\n",
    "$$\n",
    "\n",
    "* **Hint:** See the cell above for an example of working with [dt accessors](https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#dt-accessor). You should use the `est_time` column to calculate the hour.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4b-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "trump['hour'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q4c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 4b\n",
    "\n",
    "Use this data along with the seaborn `distplot` function to examine the distribution over hours of the day in eastern time that Trump tweets on each device for the 2 most commonly used devices.  Your final plot should look similar to the following:\n",
    "\n",
    "<img src=\"images/device_hour4b.png\" width=\"600px\" />\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4b\n",
    "points: 2\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q4c-answer",
     "locked": false,
     "points": 2,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### make your plot here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q4d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 4c\n",
    "\n",
    "According to [this Verge article](https://www.theverge.com/2017/3/29/15103504/donald-trump-iphone-using-switched-android), Donald Trump switched from an Android to an iPhone sometime in March 2017.\n",
    "\n",
    "Let's see if this information significantly changes our plot. Create a figure similar to your figure from question 4b, but this time, only use tweets that were tweeted before 2017. Your plot should look similar to the following:\n",
    "\n",
    "<img src=\"images/device_hour4c.png\" width=\"600px\" />\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4c\n",
    "points: 2\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9d60149ec24272e3",
     "locked": false,
     "points": 0,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### make your plot here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 4d\n",
    "\n",
    "During the campaign, it was theorized that Donald Trump's tweets from Android devices were written by him personally, and the tweets from iPhones were from his staff. Does your figure give support to this theory? What kinds of additional analysis could help support or reject this claim?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4d\n",
    "points: 1\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6-header",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "# Part 3: Sentiment Analysis\n",
    "\n",
    "It turns out that we can use the words in Trump's tweets to calculate a measure of the sentiment of the tweet. For example, the sentence \"I love America!\" has positive sentiment, whereas the sentence \"I hate taxes!\" has a negative sentiment. In addition, some words have stronger positive / negative sentiment than others: \"I love America.\" is more positive than \"I like America.\"\n",
    "\n",
    "We will use the [VADER (Valence Aware Dictionary and sEntiment Reasoner)](https://github.com/cjhutto/vaderSentiment) lexicon to analyze the sentiment of Trump's tweets. VADER is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media which is great for our usage.\n",
    "\n",
    "The VADER lexicon gives the sentiment of individual words. Run the following cell to show the first few rows of the lexicon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "head-vader",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(''.join(open(\"vader_lexicon.txt\").readlines()[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the lexicon contains emojis too! Each row contains a word and the *polarity* of that word, measuring how positive or negative the word is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q6a-header",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Question 5\n",
    "\n",
    "The creators of VADER describe the tool’s assessment of polarity, or “compound score,” in the following way:\n",
    "\n",
    "“The compound score is computed by summing the valence scores of each word in the lexicon, adjusted according to the rules, and then normalized to be between -1 (most extreme negative) and +1 (most extreme positive). This is the most useful metric if you want a single unidimensional measure of sentiment for a given sentence. Calling it a 'normalized, weighted composite score' is accurate.”\n",
    "\n",
    "As you can see, VADER doesn't \"read\" sentences, but works by parsing sentences into words assigning a preset generalized score from their testing sets to each word separately. \n",
    "\n",
    "VADER relies on humans to stabilize its scoring. The creators use Amazon Mechanical Turk, a crowdsourcing survey platform, to train its model. Its training set of data consists of a small corpus of tweets, New York Times editorials and news articles, Rotten Tomatoes reviews, and Amazon product reviews, tokenized using the natural language toolkit (NLTK). Each word in each dataset was reviewed and rated by at least 20 trained individuals who had signed up to work on these tasks through Mechanical Turk. \n",
    "\n",
    "### Question 5a\n",
    "\n",
    "Please score the sentiment of one of the following words:\n",
    "- police\n",
    "- order\n",
    "- Democrat\n",
    "- Republican\n",
    "- gun\n",
    "- dog\n",
    "- technology\n",
    "- TikTok\n",
    "- security\n",
    "- face-mask\n",
    "- science\n",
    "- climate change\n",
    "- vaccine\n",
    "\n",
    "What score did you give it and why? Can you think of a situation in which this word would carry the opposite sentiment to the one you’ve just assigned?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5a\n",
    "points: 1\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 5b\n",
    "VADER aggregates the sentiment of words in order to determine the overall sentiment of a sentence, and further aggregates sentences to assign just one aggregated score to a whole tweet or collection of tweets. This is a complex process and if you'd like to learn more about how VADER aggregates sentiment, here is the info at this [link](https://github.com/cjhutto/vaderSentiment#introduction).\n",
    "\n",
    "Are there circumstances (e.g. certain kinds of language or data) when you might not want to use VADER? What features of human speech might VADER misrepresent or fail to capture?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5b\n",
    "points: 1\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Question 5c\n",
    "\n",
    "Read `vader_lexicon.txt` into a DataFrame called `sent`. The index of the DataFrame should be the words in the lexicon. `sent` should have one column named `polarity`, storing the polarity of each word.\n",
    "\n",
    "* **Hint:** The `pd.read_csv` function may help here. Since the file is tab-separated, be sure to set `sep='\\t'` in your call to `pd.read_csv`. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5c\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6a1",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "sent = ...\n",
    "sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q6b-header",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 5d\n",
    "\n",
    "Now, let's use this lexicon to calculate the overall sentiment for each of Trump's tweets. Here's the basic idea:\n",
    "\n",
    "1. For each tweet, find the sentiment of each word.\n",
    "2. Calculate the sentiment of each tweet by taking the sum of the sentiments of its words.\n",
    "\n",
    "First, let's lowercase the text in the tweets since the lexicon is also lowercase. Set the `text` column of the `trump` DataFrame to be the lowercased text of each tweet.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5d\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6b-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "...\n",
    "trump.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q6c-header",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 5e\n",
    "\n",
    "Now, let's get rid of punctuation since it will cause us to fail to match words. Create a new column called `no_punc` in the `trump` DataFrame to be the lowercased text of each tweet with all punctuation replaced by a single space. We consider punctuation characters to be *any character that isn't a Unicode word character or a whitespace character*. You may want to consult the Python documentation on regex for this problem.\n",
    "\n",
    "(Why don't we simply remove punctuation instead of replacing with a space? See if you can figure this out by looking at the tweet data.)\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5e\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6c",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Save your regex in punct_re\n",
    "punct_re = r''\n",
    "trump['no_punc'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q6d-header",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 5f\n",
    "\n",
    "Now, let's convert the tweets into what's called a [*tidy format*](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html) to make the sentiments easier to calculate. Use the `no_punc` column of `trump` to create a table called `tidy_format`. The index of the table should be the IDs of the tweets, repeated once for every word in the tweet. It has two columns:\n",
    "\n",
    "1. `num`: The location of the word in the tweet. For example, if the tweet was \"i love america\", then the location of the word \"i\" is 0, \"love\" is 1, and \"america\" is 2.\n",
    "2. `word`: The individual words of each tweet.\n",
    "\n",
    "The first few rows of our `tidy_format` table look like:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>num</th>\n",
    "      <th>word</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>690171032150237184</th>\n",
    "      <td>0</td>\n",
    "      <td>bigop1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>690171032150237184</th>\n",
    "      <td>1</td>\n",
    "      <td>realdonaldtrump</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>690171032150237184</th>\n",
    "      <td>2</td>\n",
    "      <td>sarahpalinusa</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>690171032150237184</th>\n",
    "      <td>3</td>\n",
    "      <td>https</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>690171032150237184</th>\n",
    "      <td>4</td>\n",
    "      <td>t</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "**Note that your DataFrame may look different from the one above.** However, you can double check that your tweet with ID `894661651760377856` has the same rows as ours. Our tests don't check whether your table looks exactly like ours.\n",
    "\n",
    "As usual, try to avoid using any for loops. Our solution uses a chain of 5 methods on the `trump` DataFrame, albeit using some rather advanced Pandas hacking.\n",
    "\n",
    "* **Hint 1:** Try looking at the `expand` argument to pandas' `str.split`.\n",
    "\n",
    "* **Hint 2:** Try looking at the `stack()` method.\n",
    "\n",
    "* **Hint 3:** Try looking at the `level` parameter of the `reset_index` method.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5f\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6d-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "tidy_format = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q6e-header",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 5g\n",
    "\n",
    "Now that we have this table in the tidy format, it becomes much easier to find the sentiment of each tweet: we can join the table with the lexicon table. \n",
    "\n",
    "Add a `polarity` column to the `trump` table.  The `polarity` column should contain the sum of the sentiment polarity of each word in the text of the tweet.\n",
    "\n",
    "**Hints:** \n",
    "* You will need to merge the `tidy_format` and `sent` tables and group the final answer.\n",
    "* If certain words are not found in the `sent` table, set their polarities to 0.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5g\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6e",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "trump['polarity'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "a-note-on-vader",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Now we have a measure of the sentiment of each of his tweets! Note that this calculation is rather basic; you can read over the VADER readme to understand a more robust sentiment analysis.\n",
    "\n",
    "Now, run the cells below to see the most positive and most negative tweets from Trump in your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "negative-tweets",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print('Most negative tweets:')\n",
    "for t in trump.sort_values('polarity').head()['text']:\n",
    "    print('\\n  ', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "postive-tweets",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Most positive tweets:')\n",
    "for t in trump.sort_values('polarity', ascending=False).head()['text']:\n",
    "    print('\\n  ', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Question 5h\n",
    "\n",
    "Read the 5 most positive and 5 most negative tweets. Do you think these tweets are accurately represented by their polarity scores?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5h\n",
    "points: 1\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q6g",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Question 6\n",
    "\n",
    "Now, let's try looking at the distributions of sentiments for tweets containing certain keywords.\n",
    "\n",
    "### Question 6a\n",
    "\n",
    "In the cell below, create a single plot showing both the distribution of tweet sentiments for tweets containing `nytimes`, as well as the distribution of tweet sentiments for tweets containing `fox`.\n",
    "\n",
    "Be sure to label your axes and provide a title and legend. Be sure to use different colors for `fox` and `nytimes`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6a\n",
    "points: 1\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q6g-answer",
     "locked": false,
     "points": 1,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "comment-on-faux-news",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6b\n",
    "Comment on what you observe in the plot above. Can you find another pair of keywords that lead to interesting plots? Describe what makes the plots interesting. (If you modify your code in 6a, remember to change the words back to `nytimes` and `fox` before submitting for grading).\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6b\n",
    "points: 1\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see whether there's a difference in sentiment for tweets with hashtags and those without."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 7a\n",
    "First, we'll need to write some regex that can detect whether a tweet contains a hashtag or a link. We say that:\n",
    "\n",
    "- A tweet is a retweet if it has the string 'rt' anywhere in the tweet if it is preceeded and followed by a non-word character (the start and end of the string count as non-word characters).\n",
    "- A tweet has a hashtag if it has the character '#' anywhere in the tweet followed by a letter.\n",
    "- A tweet contains a link or a picture if it has `http` anywhere in the tweet\n",
    "\n",
    "(You can check out Trump's Twitter for why these criteria are true).\n",
    "\n",
    "In the cell below, assign `rt_re` to a regex pattern that identifies retweets and `hash_link_re` to a regex pattern that identifies tweets with hashtags or links.\n",
    "\n",
    "**Hints**: \n",
    "- Be sure to precede your regex pattern with `r` to make it a raw string (Ex: `r'pattern'`). To find out more, you can read the first paragraph of the [documentation](https://docs.python.org/2/library/re.html).\n",
    "- You may find using regex word boundaries helpful for one of your patterns. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7a\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_re = ...\n",
    "hash_link_re = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7b\n",
    "Let's see whether there's a difference in sentiments for tweets with hashtags/links and those without. \n",
    "\n",
    "*Note: You will get a UserWarning error when running the below cell. For the purpose of this homework, you can ignore it.*\n",
    "\n",
    "Run the cell below to see a distribution of tweet sentiments based on whether a tweet contains a hashtag or link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(trump[trump['text'].str.contains(hash_link_re)]['polarity'],label='hashtag or link');\n",
    "sns.distplot(trump[~trump['text'].str.contains(hash_link_re)]['polarity'],label='no hashtag or link');\n",
    "plt.xlim(-10, 10);\n",
    "plt.ylim(0, 0.4);\n",
    "plt.title('Distribution of Tweet Polarities (hashtag/link vs none)');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "What do you notice about the distributions? Answer in 1-2 sentences.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7b\n",
    "points: 1\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## Congratulations! You have finished Homework 4!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(\"hw4.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
