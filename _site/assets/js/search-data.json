{
  "0": {
    "id": "0",
    "title": "Announcements",
    "content": "Announcements Announcements are stored in the _announcements directory and rendered according to the layout file, _layouts/announcement.html. Week 0 Announcements Welcome to Data 100! We’re still getting this site set up. Some information here may be inaccurate. We will remove this warning once the site is complete. Announcements We will not be updating this page with announcements. For the latest announcements, make sure to check our Piazza.",
    "url": "http://localhost:4000/fa20/announcements/",
    "relUrl": "/announcements/"
  },
  "1": {
    "id": "1",
    "title": "Calendar",
    "content": "Calendar Discussion, Lab, and Special Events Calendar Office Hours Calendar Discussion, Lab, and Special Events Calendar This calendar contains times for live discussion sessions (in red) live lab sessions (in blue) other special events, such as lost office hours (in yellow) To access these events, use the Zoom links posted in @15 on Piazza. Office Hours Calendar GSI and tutor office hours are in grey. Click on each event to see which GSI or tutor is running each office hour time. You should come to these with questions about anything – labs, homeworks, projects, discussions, concepts, etc. To access GSI and tutor office hours, go to our Office Hours Queue. When it’s your turn, you will be given the Zoom link to join. Prof. Joseph and Prof. Perez’ office hours are in dark pink. You should come to these with questions about concepts. To access instructor office hours, use the Zoom links posted on Piazza. Lost office hours are also in dark pink. You should come to these if you feel behind in the course and would like help with the material (but not with assignments).",
    "url": "http://localhost:4000/fa20/calendar/",
    "relUrl": "/calendar/"
  },
  "2": {
    "id": "2",
    "title": "Graduate Project",
    "content": "Graduate Project The graduate project is offered only to students enrolled in Data C200 or CS C200A. Other students are welcome to explore the questions and datasets in the project for learning, but their work will not be graded or counted towards their final grades. The purpose of the project is to give students experience in both open-ended data science analysis and research in general. As part of the project, you have the option to either [Option 1] work with a combination of datasets provided to you to explore research questions that you define. [Option 2] complete the computer vision project. Note: each option has its own set of requirements for Report Format and Submission. Be sure to consult the correct section for your project option. You will receive feedback from peer grading before the final deadline, and you are expected to incorporate the feedback into the final report and presentation. You will be graded on both the final report and presentation, as well as deliverables before the submission of the final reports, including your peer reviews. Teamwork: You can work alone or in a group with at most two other students. If you are interested in working with others, we will have a Piazza post for teammate search. Everyone in the same group will receive the same grade. The group size will be taken into consideration for grading. Option 1: Multiple Datasets This project option involves studying two or more of the following datasets. You are welcome to bring in additional datasets to complement the datasets provided here, but you must cite the sources and clearly describe the content of any additional data you use in the final report. Please be sure to consult the references on causal inference for guidance on how to work with multiple datasets. Datasets The following datasets can be found in ~/shared/grad_proj/multiple_datasets on DataHub. If you wish to work on the project locally, you can download ~/shared/grad_proj/multiple_datasets.zip containing all the datasets. COVID-19 This dataset contains global and US daily reports on testing and cases from the COVID-19 Data Repository by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University. It is located at ~/shared/grad_proj/multiple_datasets/covid on DataHub, and the global reports and US reports are located in two separate directories: csse_covid_19_daily_reports contains global daily reports (documentation) csse_covid_19_daily_reports_us contains US daily reports (documentation) You can choose to work with either the global reports or the US reports. You are not required to study both if you were to choose this dataset. Mental Health in Tech Survey This dataset contains questions and answers in the OSMI Mental Health in Tech Survey conducted annually between 2014 and 2019. It is located at ~/shared/grad_proj/multiple_datasets/mental_health on DataHub and comprises two tables: mental_health_question.csv contains the questions and their IDs in QuestionText and QuestionID respectively. mental_health_answer.csv contains the survey participants’ answers to the questions in AnswerText. SurveyID is the year in which the survey is conducted, and QuestionID matches the QuestionID in mental_health_question.csv. Each row corresponds to the answer to a specific question by a specific user identified by UserID. Note that the set of questions asked in the survey changes from year to year. Global Climate This dataset contains the daily temperature and precipitation measured by weather stations in the Global Historical Climatology Network for January to October 2020. This dataset can be found in ~/shared/grad_proj/multiple_datasets/climate on DataHub. The data in daily_global_weather_2020.csv is derived from the source file at https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/2020.csv.gz. To help you get started with a dataset of manageable size, we have preprocessed the GHCN dataset to include only the average temperature and precipitation measurements from stations that have both measurements. Each row in the preprocessed dataset contains both the average temperature and precipitation measurements for a given station on a given date. If you wish to explore the climate data for a different year, you can use the GHCN_data_preprocessing.ipynb notebook to download and perform the preprocessing described above. Please be advised that depending on the dataset size for a given year, GHCN_data_preprocessing.ipynb may not run on DataHub. We will not be providing infrastructural support for running the notebook, but you are welcome to run it on a different machine you have access to or ask a GSI to dump the data for you. This dataset contains only the (latitude, longitude) coordinates for the weather stations. To map the coordinates to geographical locations, the reverse-geocoder package mentioned in the References section might be helpful. 2019 US Census The 2019 US Census dataset contains demographic, housing and economic information reported at the county level. The dataset is located at ~/shared/grad_proj/multiple_datasets/census on DataHub and comprises two tables: DP05: ACS Demographic and Housing Estimates (exported from the DP05 table at county level summary from data.census.gov). DP03: Selected Economic Characteristics (exported from the DP03 table at county level summary from data.census.gov). Documentation for these two tables can be found in DP03/ACSDP1Y2019.DP03_table_title.txt and DP05/ACSDP1Y2019.DP05_table_title.txt, respectively. You can also visit data.census.gov for more information on the datasets. Example Research Questions Involving Multiple Datasets COVID-19 + Climate: Does weather have an effect on the spread of COVID-19? How do we control for test availability and differences in response to the disease? Here are some existing studies on the topic. COVID-19 + Mental Health: Are there specific populations that are particularly susceptible to both COVID-19 and mental health ailments? COVID-19 + US Census: what is the relationship between COVID-19 cases and socioeconomic factors and healthcare coverage? Can you use demographic features to predict COVID-19 infection and mortality rates? Report Format and Submission The project submission should include the following two components. Analysis Notebooks. The Jupyter Notebook(s) containing all the analyses that you performed on the datasets to support your claims in the narrative notebook. Make sure that all references to datasets are done as data/[path to data files]. You can copy the datasets from ~/shared/grad_proj/multiple_datasets into data/ at the top-level directory for your project on DataHub to do this. Narrative Notebook. This is a single Jupyter Notebook that summarizes your workflow and what you have learned. It should be structured as a research paper and include a title, list of authors, abstract, introduction, description of data, description of methods, summary of results, and discussion. Make sure to number figures and tables and include informative captions. UPDATE: you can now replace the narrative notebook, and only the narrative notebook, with a PDF compiled using LaTeX, provided that the provenance of the figures are clearly labeled in the main narrative, and the figures can be reproduced by running the analysis notebooks Specifically, you should address the following in the narrative: Clearly stated research questions and why they are interesting and important. You must include at least one research question involving multiple datasets, but you may include additional research questions about each individual dataset. At least one of your research questions has to include a modeling component, e.g., can we build a model using climate data to predict growth in COVID-19 cases accurately? The modeling question does not need to be about multiple datasets. A brief survey of related work on the topic(s) of your analysis and how your project differs from or complements existing research. If applicable, descriptions of additional datasets that you gathered to support your analysis. Methodology: carefully describe the methods you use and why they are appropriate for answering your search questions. It must include a brief overview of causal inference, which should be written in a way such that another student in Data 100 who has never been exposed to the concept can carry out the analyses involving multiple datasets in your project. a detailed description of how modeling is done in your project, including inference or prediction methods used, feature engineering and regularization if applicable, and cross-validation or test data as appropriate for model selection and evaluation. Interesting findings* about each dataset when analyzed individually. Include visualizations and descriptions of data cleaning and data transformation necessary to perform the analysis that led to your findings. Interesting findings* involving multiple datasets. Include visualizations and descriptions of data cleaning and data transformation necessary to perform the analysis that led to your findings. Analysis of your findings to answer your research question(s). Include visualizations and specific results. If your research questions contain a modeling component, you must compare the results using different inference or prediction methods (e.g., linear regression, logistic regression, or classification and regression trees). Can you explain why some methods performed better than others? An evaluation of your approach and discuss any limitations of the methods you used. Describe any surprising discoveries that you made and future work. * Examples of interesting findings: interesting data distributions and trends, correlations between different features, the relationship between the data distribution for the general population and specific datasets (e.g., the gender distribution in the census dataset vs. in the mental health dataset), specific features that are notably effective/ineffective for prediction. The narrative notebook should include figures sparingly to support specific claims. It can include runnable components, but it should not have large amounts of code. The length of the report should be 8+/-2 pages when it is printed as a PDF, excluding figures and code. Tip: if you need to write a large amount of $ LaTeX$, you may want to use the %%latex cell magic. Please submit everything as a zip file to submission link TBA. Please make sure the folder in the zip file has the following structure: studentIDs/ data/[all datasets used] analysis/[analysis notebooks] narrative/[narrative notebook] figures/[figures included in the narrative notebook] For groups with multiple members, please use student IDs joined by _ as the name for the top-level directory. The analysis notebooks must be runnable within this directory structure. If the narrative notebook includes any figures that are created in the analysis notebooks, the figures should be saved to figures/ by the analysis notebooks and imported from figures/ by the narrative notebook. Option 2: Image Classification For the image classification project, you are provided with a set of “real-world” images of 20 different types (e.g., “dog”, “goat”) and your task is to train and evaluate several predictors for the class of an image. You will then evaluate your proposed final classifier using a test set for which we have withheld the class labels. Everything you need for the project can be found in ~/shared/grad_proj/computer_vision on DataHub. Dataset The dataset for training and validation, referred to simply as the training set from here on, consists of a total of 2,921 images, of 20 different types and of possibly different sizes (i.e., numbers of pixels). Each image is represented as 3-d array with the first two dimensions corresponding to the row and column pixels and third dimension to the color. The third dimension size is always 3, and each value corresponds to a red, green, or blue (RGB) color intensity between 0 and $2^8 - 1$. The training set can be found in the 20 categories training folder in the project starter directory. The test set can be found in the 20 validation folder in the project starter directory. Project Guidelines The project involves carrying through the following steps. Data Input Read in all the provided training and test set images. Store the images in two data frames, one for the training set (with class labels) and one for the test set (without class labels). Exploratory data analysis and feature extraction. (Training set only.) Display three of the training set images. Provide graphical summaries of the sizes of the images, pixel intensities, and class frequencies. Provide functions that summarize pixel intensity data (e.g., https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_table_of_contents_feature2d/py_table_of_contents_feature2d.html#py-table-of-content-feature2d). Compute at least 15 such image features (a method for each), including the following (NOTE: At least 10 of these must be scalar features and 2 matrix-based features): (i) image size, (ii) average of the red-channel intensity, (iii) aspect ratio. Examine how these image features vary between classes. Classifier training. (Training set only.) Using all or a selected subset of the features from Step 2 and all or a selected subset of individual pixel intensities, build the following classifiers using only the training set. Feel free to generate a combination of these models for your final predictions. Logistic regression: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html. k-nearest neighbors (kNN): http://scikitlearn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html. Classification tree: https://scikit-learn.org/stable/modules/tree.html. Random Forests: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html. Support vector machines (SVM): http://scikit-learn.org/stable/modules/svm.html. Classifier performance assessment. (Training set only.) Evaluate the performance of the classifiers in Step 3 using five-fold cross-validation of the training set to estimate the misclassification error rate, i.e., perform all the tasks in Step 3) (including feature selection) on the training sets and compute misclassification rates on the validation sets. Neural networks. (Optional. Extra credit: 10% (out of 100%) of project score, but your total project score cannot exceed 100%.) Build a neural network classifier using an architecture of your choosing. This application of deep learning can be done in PyTorch, TensorFlow, or a framework of your choice. Describe your network and assess its performance. To receive extra credit, your neural network classifier must outperform your other methods. Report Format and Submission The project submission should include the following three components. Jupyter Notebooks. Use the provided starter notebooks to complete the following aspects of the project. Data input. Exploratory data analysis and feature extraction. Classifier training and performance assessment. Neural networks (Extra credit). Note: We will run the notebooks in that order when grading, so please account for that. Project narrative. This Jupyter Notebook should summarize your workflow and what you have learned. It should be structured as a research paper and include a title, list of authors, abstract, introduction, description of data, description of methods, summary of results, and discussion. Make sure to number figures and tables and include informative captions. UPDATE: you can now replace the narrative notebook, and only the narrative notebook, with a PDF compiled using LaTeX, provided that the provenance of the figures are clearly labeled in the main narrative, and the figures can be reproduced by running the analysis notebooks Specifically, you should address the following in the narrative. Frame the question. Describe the data. Perform exploratory data analysis (EDA) and provide data visualizations. Describe any data cleaning or transformations that you perform and why they are motivated by your EDA. Carefully describe the methods you are using and why they are appropriate for the question to be answered. Summarize and interpret your results (including visualization). Address the following three specific questions. (i) What were two or three of the most interesting features you came across? Describe the process of finding those features. (ii) Describe one feature you thought would be useful but turned out to be ineffective. (iii) Describe the differences in the classifiers that you used. Why did some work better than others? Which turned out to be the most effective? Provide an evaluation of your approach and discuss any limitations of the methods you used. Describe any surprising discoveries that you made and future work. The narrative notebook should include figures sparingly to support specific claims. It can include runnable components, but it should not have large amounts of code. The length of the report should be 8+/-2 pages when it is printed as a PDF, excluding figures and code. Image class predictions for test set. Run the classifier of your choice on the test data of 716 images and generate a CSV file of the classification for each image. Submit this CSV file on Gradescope (only needed for the final report, not peer review). It is your responsibility to follow the order of the files when creating the CSV (predict validation 1 before validation 2…). Note 1: You are not to use the test data in any way for training or creating your classifer. Note 2: You are not allowed to use a neural network for your final classifier. The accuracy of your final classifier on the test set will count for 25% of your grade on the final report. Please submit the notebooks only as a zip file to submission link TBA. Use relative paths instead of absolute paths in your notebooks to faciliate notebook rerun. For groups with multiple members, please use student IDs joined by _ as the name for the top-level directory. Deliverable Deadlines Summary of deadlines and grade breakdown Deliverable Deadline % Grade (out of 100%) Project Signup November 12th, 11:59 pm PT 5% (full credit for submitting on time) Proposal November 17th 18th, 11:59 pm PT 5% (full credit for submitting on time) Report draft for peer review November 24th, 11:59 pm PT 5% (full credit for submitting on time) Peer reviews December 1st, 11:59 pm PT 10% (peer review rubric) Final report and presentation December 9th, 11:59 pm PT 75% (rubric TBD) Datasets selection and group signup (Due 11:59pm PT, November 12th) Please sign up with your group and dataset selections here by November 12th. Only one person per partner group needs to fill out the form. If you are interested in working with another student, we will have a Piazza post for teammate search. You are encouraged but not required to explore all datasets provided before deciding on the datasets to use for your project. This accounts for 5% (out of 100%) of your project grade. You will receive full credit for submitting the signup form by the deadline. Research questions and proposed methodology (Due 11:59pm PT, November 17th 18th) A one-page PDF document addressing the following questions: What are the research questions you are tackling in your project? What are some existing works, if any, related to your research questions? If you selected Option 2, talk about what questions you’d like to explore for the image dataset. What data analysis do you plan on performing for each dataset to help answer your research questions? [Option 1 only] How does causal inference apply to the analysis you plan on doing involving multiple datasets? What is the difference between causation and association? What are potential sources of confounding? How do you identify and adjust for it? [Option 2 only] How do you plan on testing your classifier? Consult the textbooks in References or other reputable materials you find to answer these questions. Make sure to cite any reference materials and related work. You will submit the proposal via Gradescope. The proposal accounts for 5% (out of 100%) of your project grade. You will receive full credit for submitting the proposal by the deadline. Report submission for peer review (Due 11:59pm PT, November 24th) An initial draft of your report to be shared with other groups in the class for peer review. You will not be graded on the quality of this draft, but feedback from your peers may be taken into consideration for the final grade. Follow the instructions in the Report Format and Submission section of the project option that you chose to prepare the zip file to be submitted via this Google Form. This accounts for 5% (out of 100%) of your project grade. You will receive full credit for submitting the report by the deadline. Late reports might not be able to participate in peer review, and peer feedback will be taken into consideration for the final report grade. Note for Option 2: do NOT include the prediction CSV in the zip file. You are welcome to redact certain information in the peer review version to prevent plagiarism. Make sure to anonymize your report for this submission. That means the names of the group members should not be shown anywhere in the report notebooks. Peer Review Submission (Due 11:59pm PT, December 1st) Each group will peer grade (2 * group size) other projects. For each project reviewed, the review should include the following components: A score between 1 to 5 (5 is the best). A summary of the report &amp; rationale for the score 3 strong points 3 weak points Detailed feedback (&gt;= 3 suggestions for improvement) This accounts for 10% (out of 100%) of your project grade. You will be graded on the quality of your reviews using the peer review rubric, and your peers will take your reviews into consideration when preparing their reports for the final submission. Your reviews will be disseminated to your peers shortly after the deadline, so it is important that your reviews are submitted on time. You will submit your reviews via this Google Form. Final report &amp; presentation submission (Due 11:59pm PT, December 9th) The final submission contains two parts: The zip file containing all of the necessary components of the report according to the instructions in in the Report Format and Submission section of the project option that you chose. A two-minute video walkthrough of your report. You are expected to incorporate feedback from peer review into the final report. You will submit a single zip file containing the following directory structure when decompressed: studentIDs studentIDs_final_report.zip peer_review review1.pdf ... studentIDs.mp4 This accounts for 75% (out of 100%) of your project grade. Rubric to be released after the proposal deadline. References Working with Geographical Coordinates For datasets containing only latitude and longitude information, you may want to use the reverse-geocoder Python package to help you map the coordinates to geographic regions. Tip: when using reverse-geocoder, you might want to run queries in bulk instead of one coordinate at a time, e.g., import reverse_geocoder as rg query = rg.search([tuple(x) for x in df[[&#39;Latitude&#39;, &#39;Longitude&#39;]].values]) We have also provided a mapping from country codes to country names and regions in UID_ISO_FIPS_LookUp_Table.csv. Be sure to read the documentation for reverse-geocoder to decide what type of country codes to use for the join. Causal Inference When studying the relationship between datasets, you might want to consult the following references on causality vs. correlation. Oftentimes, it is tempting to make claims about causal relationships when there is not enough evidence from the data to support such claims. Please review the following references, or other reputable references that you find on the topic to familiarize yourself with relevant concepts and methods. Data 102 Data, Inference, and Decisions Spring 2020: Lecture 13: Causal Inference I. Moritz Hardt. Hernán MA, Robins JM (2020). Causal Inference: What If. Boca Raton: Chapman &amp; Hall/CRC. Advanced Data Analysis from an Elementary Point of View by Cosma Rohilla Shalizi",
    "url": "http://localhost:4000/fa20/gradproject/",
    "relUrl": "/gradproject/"
  },
  "3": {
    "id": "3",
    "title": "Home",
    "content": "Principles and Techniques of Data Science UC Berkeley, Fall 2020 Anthony Joseph adj@berkeley.edu Fernando Perez fernando.perez@berkeley.edu All announcements are on Piazza. Make sure you are enrolled and active there. Please read our course FAQ before contacting staff with questions that might be answered there. The Syllabus contains a detailed explanation of how each course component will work this fall, given that the course is being taught entirely online. The scheduling of all weekly events is in the Calendar. The Zoom links for all live events are in @15 on Piazza. Week 1 Aug 26 N/A Aug 27 Lecture 1 Introduction, Course Overview (QC due Aug. 31) Ch. 1 Aug 28 Homework 1 Prerequisites (due Sept. 3) Week 2 Aug 31 Lab 1 Prerequisite Coding (due Aug. 31) Sep 1 Lecture 2 Data Sampling and Probability (QC due Sept. 8) Ch. 2 Sep 2 Discussion 1 Linear Algebra and Probability (video) (solutions) Sep 3 Lecture 3 Random Variables (QC due Sept. 8) Ch. 12.1-12.2 Sep 4 Homework 2 Trump Sampling (due Sept. 10) Week 3 Sep 8 Lab 2 SQL (due Sept. 8th) Sep 8 Lecture 4 SQL (QC due Sept. 14) Ch. 9 Sep 9 Discussion 2 Random Variables and SQL (video) (solutions) Sep 10 Lecture 5 Pandas I (QC due Sept. 14) Ch. 3 Sep 11 Project 1 Food Safety (due Sept. 24) Week 4 Sep 14 Lab 3 Pandas I (due Sept. 14) Sep 15 Lecture 6 Pandas II (QC due Sept. 21) Ch. 3 Sep 16 Discussion 3 Pandas (video) (solutions) Sep 17 Lecture 7 Data Cleaning and EDA (QC due Sept. 21) Ch. 4.1, Ch. 5 Sep 18 N/A Week 5 Sep 21 Lab 4 Data Cleaning and EDA (due Sept. 21) Sep 22 Lecture 8 Regular Expressions (QC due Sept. 28) Ch. 8 Sep 23 Discussion 4 Regex (notebook) (video) (solutions) Sep 24 Lecture 9 Visualization I (QC due Sept. 28) Ch. 6.1-6.3 Sep 25 Homework 3 Bike Sharing (due Oct. 1) Week 6 Sep 28 Lab 5 Transformations and KDEs (due Sept. 28) Sep 29 Lecture 10 Visualization II (QC due Oct. 5) Ch. 6.4-6.6 Sep 30 Discussion 5 Visualizations (notebook) (video) (solutions) Oct 1 Lecture 11 Modeling (QC due Oct. 5) Ch. 10 Oct 2 Homework 4 Trump Tweets (due Oct. 8) Week 7 Oct 5 Lab 6 Modeling, Summary Statistics, and Loss Functions (due Oct. 5) Oct 6 Lecture 12 Simple Linear Regression (QC due Oct. 12) Ch. 13.1-13.3 Oct 7 Discussion 6 Modeling and Linear Regression (video) (solutions) Oct 8 Lecture 13 Ordinary Least Squares (QC due Oct. 12) Ch. 13.4 Oct 9 Homework 5 Regression (due Oct. 22) Week 8 Oct 12 Lab 7 Simple Linear Regression (due Oct. 12) Oct 13 Review Sessions Midterm Review Oct 14 Discussion 7 Least Squares (video) (solutions) Oct 15 Exam Midterm (7-9PM PDT) Oct 16 N/A Week 9 Oct 19 N/A Oct 20 Lecture 14 Feature Engineering (QC due Oct. 26) Ch. 14 Survey Mid-Semester Survey (due Oct. 26) Oct 21 Discussion 8 Feature Engineering and Midterm Review (video) (solutions) Oct 22 Lecture 15 Bias and Variance (QC due Oct. 26) Ch. 12, 15.1-15.2 Oct 23 Homework 6 Housing (due Nov. 6) Week 10 Oct 26 Lab 8 Multiple Linear Regression and Feature Engineering (due Oct. 26) Oct 27 Lecture 16 Cross-Validation and Regularization (QC due Nov. 2) Ch. 16, Ch. 15.3 Oct 28 Discussion 9 Bias &amp; Variance, Cross-Validation, &amp; Regularization (video) (solutions) Oct 29 Lecture 17 Gradient Descent (QC due Nov. 2) Ch. 11 Oct 30 N/A Week 11 Nov 2 Lab 9 Feature Engineering &amp; Cross-Validation (due Nov. 2) Nov 3 N/A (Election Day) Nov 4 Discussion 10 Gradient Descent (video) (solutions) Nov 5 Lecture 18 Logistic Regression I (QC due Nov. 9) Ch. 17.1-17.3 Nov 6 Homework 7 Gradient Descent and Logistic Regression (due Nov. 12) Week 12 Nov 9 Lab 10 Logistic Regression (due Nov. 9) Graduate Project Graduate Project Nov 10 Lecture 19 Logistic Regression II, Classification (QC due Nov. 16) Ch. 17.4-17.7 Nov 11 Discussion 11 Logistic Regression (video) (solutions) Nov 12 Lecture 20 Decision Trees (QC due Nov. 16) Nov 13 Project 2 Spam/Ham (due Nov. 30) Week 13 Nov 16 Lab 11 Decision Trees and Random Forests (due Nov. 16) Nov 17 Lecture 21 Inference for Modeling (QC due Nov. 23) Ch. 18.1, 18.3 Nov 18 Discussion 12 Decision Trees &amp; Inference (video) Nov 19 Lecture 22 Principal Components Analysis (QC due Nov. 23) Nov 20 Homework 8 PCA (due Dec. 3) Week 14 Nov 23 Lab 12 Principal Component Analysis (due Nov. 23) Live Session AMA with Professors (9-10AM PST) Nov 24 Lecture 23 Clustering (QC due Nov. 30) Nov 25 N/A (Thanksgiving) Nov 26 N/A (Thanksgiving) Nov 27 N/A Week 15 Nov 30 Lab 13 Using the Bootstrap for Estimation (due Dec. 7) Dec 1 Lecture 24 Big Data (QC due Dec. 7) Dec 2 Discussion 13 PCA, Clustering, &amp; Big Data (video) Dec 3 Lecture 25 Conclusion (live, 9:30-11AM PST) Dec 4 N/A Week 16 (RRR Week) Dec 8 Review Dec 10 Review Week 17 (Finals Week) Dec 15 Exam Final Exam (7-10PM PST)",
    "url": "http://localhost:4000/fa20/",
    "relUrl": "/"
  },
  "4": {
    "id": "4",
    "title": "Lecture 1 – Introduction, Course Overview",
    "content": "Lecture 1 – Introduction, Course Overview Presented by Anthony D. Joseph and Fernando Perez Content by Suraj Rampure, Allen Shen, Joseph Gonzalez, Josh Hug, and Sam Lau slides video playlist code code HTML Welcome to Data 100, and to a new lecture format! The right column of the table below contains Quick Checks. These are required – they are worth 5% of your grade if you are an undergraduate – but are graded on completion, not correctness. A random one of the following six Google Forms will give you an alphanumeric code once you submit; you should take this code and enter it into the “Lecture 1” question in the “Quick Check Codes” assignment on Gradescope to get credit for submitting this Quick Check. You must submit this by Monday, August 31st at 11:59PM to get credit for it. Video Quick Check 1.1 Introductions from Professor Joseph and Professor Perez. 1.1 1.2 What is data science? An overview of the field, and issues to be aware of. 1.2 1.3 An overview of the topics covered in this course. 1.3 1.4 A detailed description of how each course component will run this semester. 1.4 1.5 An overview of the data science lifecycle and its four steps. 1.5 1.6 A demonstration of various data science tools using data from students in this class. 1.6",
    "url": "http://localhost:4000/fa20/lecture/lec01/",
    "relUrl": "/lecture/lec01/"
  },
  "5": {
    "id": "5",
    "title": "Lecture 2 – Data Sampling and Probability",
    "content": "Lecture 2 – Data Sampling and Probability Presented by Fernando Perez and Suraj Rampure Content by Fernando Perez, Suraj Rampure, Ani Adhikari, and Joseph Gonzalez slides video playlist A reminder – the right column of the table below contains Quick Checks. These are required – they are worth 5% of your grade if you are an undergraduate – but are graded on completion, not correctness. A random one of the following six Google Forms will give you an alphanumeric code once you submit; you should take this code and enter it into the “Lecture 2” question in the “Quick Check Codes” assignment on Gradescope to get credit for submitting this Quick Check. You must submit this by Tuesday, September 8th at 11:59PM to get credit for it. Video Quick Check 2.1 Censuses and surveys. Issues with the US Census. 2.1 2.2 Samples. Drawbacks to convenience and quota samples. 2.2 2.3 A case study in sampling bias (1936 election). 2.3 2.4 Sources of bias, and a formal definition of sampling frames. 2.4 2.5 Probability samples, and why we need them. 2.5 2.6 Introducing binomial and multinomial probability calculations. 2.6 2.7 Generalizing binomial and trinomial probability calculations. 2.7 2.8 (Extra) Using permutations and combinations to derive the binomial coefficient. 2.8 2.9 (Extra) Example usages of the binomial coefficient. 2.9",
    "url": "http://localhost:4000/fa20/lecture/lec02/",
    "relUrl": "/lecture/lec02/"
  },
  "6": {
    "id": "6",
    "title": "Lecture 3 – Random Variables",
    "content": "Lecture 3 – Random Variables Presented by Anthony D. Joseph and Suraj Rampure Content by Anthony D. Joseph, Suraj Rampure, Ani Adhikari slides video playlist (supplemental) Stat 88 chapter on distributions A random one of the following six Google Forms will give you an alphanumeric code once you submit; you should take this code and enter it into the “Lecture 3” question in the “Quick Check Codes” assignment on Gradescope to get credit for submitting this Quick Check. You must submit this by Tuesday, September 8th at 11:59PM to get credit for it. Video Quick Check 3.1 Formal definition of random variables. 3.1 3.2 Distributions of random variables. 3.2 3.3 Defining the Bernoulli and binomial distributions. 3.3 3.4 Discussing equality of random variables – equal vs. equal in distribution. 3.4 3.5 Expectation. Linearity of expectation. Sample calculations, and the expectation of the Bernoulli and binomial distributions. 3.5 3.6 Summary, and what&#39;s next. N/A",
    "url": "http://localhost:4000/fa20/lecture/lec03/",
    "relUrl": "/lecture/lec03/"
  },
  "7": {
    "id": "7",
    "title": "Lecture 4 – SQL",
    "content": "Lecture 4 - SQL Presented by Anthony D. Joseph Content by Anthony D. Joseph, Allen Shen, Josh Hug, John DeNero, Joseph Gonzalez slides video playlist code code HTML code walkthrough by Josh Hug code walkthrough by Allen Shen A random one of the following nine Google Forms will give you an alphanumeric code once you submit; you should take this code and enter it into the “Lecture 4” question in the “Quick Check Codes” assignment on Gradescope to get credit for submitting this Quick Check. You must submit this by Monday, September 14th at 11:59PM to get credit for it. Video Quick Check 4.1 Databases and database management systems. 4.1 4.2 Relational database schemas. 4.2 4.3 SQL overview and the DISTINCT keyword. 4.3 4.4 Types of joins in SQL. 4.4 4.5 NULL values in SQL. 4.5 4.6 SQL predicates and casting. 4.6 4.7 SQL sampling, subqueries, and common table expressions. 4.7 4.8 SQL CASE expressions and the SUBSTR function. 4.8 4.9 SQL summary and conclusion. 4.9",
    "url": "http://localhost:4000/fa20/lecture/lec04/",
    "relUrl": "/lecture/lec04/"
  },
  "8": {
    "id": "8",
    "title": "Lecture 5 – Pandas, Part 1",
    "content": "Lecture 5 - Pandas, Part 1 Presented by Fernando Perez Content by Fernando Perez, Josh Hug slides video playlist code code HTML Intro to Pandas if you’ve taken Data 8 (zip) A random one of the following Google Forms will give you an alphanumeric code once you submit; you should take this code and enter it into the “Lecture 5” question in the “Quick Check Codes” assignment on Gradescope to get credit for submitting this Quick Check. You must submit this by Monday, September 14th at 11:59PM to get credit for it. Video Quick Check 5.1.1 Pandas data frames, series, and indices. 5.1.1 5.1.2 Pandas indices demo. 5.1.2 5.2 Pandas indexing with the bracket operator. 5.2 5.3 Pandas boolean array selection, the isin function, and the query command. 5.3 5.4.1 Pandas indexing with .loc. 5.4.1 5.4.2 Pandas indexing with .iloc and Pandas sampling. 5.4.2 5.5.1 Pandas utility functions, properties, and the sort_values method. 5.5.1 5.5.2 The value_counts and unique methods in Pandas. An exploration of the baby names data set. 5.5.2",
    "url": "http://localhost:4000/fa20/lecture/lec05/",
    "relUrl": "/lecture/lec05/"
  },
  "9": {
    "id": "9",
    "title": "Lecture 6 – Pandas, Part 2",
    "content": "Lecture 6 - Pandas, Part 2 Presented by Fernando Perez Content by Fernando Perez, Josh Hug slides video playlist code code HTML, joins code HTML A random one of the following Google Forms will give you an alphanumeric code once you submit; you should take this code and enter it into the “Lecture 6” question in the “Quick Check Codes” assignment on Gradescope to get credit for submitting this Quick Check. You must submit this by Monday, September 21st at 11:59PM to get credit for it. Video Quick Check 6.1 Pandas string methods. 6.1 6.2 Adding, modifying, and removing columns in Pandas. 6.2 6.3 Using the Pandas groupby function for aggregation. 6.3 6.4 Puzzles using the Pandas groupby function. 6.4 6.5 Other features of the Pandas groupby function including size and filter. 6.5 6.6 Grouping by multiple columns and pivot tables in Pandas. 6.6 6.7 Joining two tables in Pandas. 6.7",
    "url": "http://localhost:4000/fa20/lecture/lec06/",
    "relUrl": "/lecture/lec06/"
  },
  "10": {
    "id": "10",
    "title": "Lecture 7 – Data Cleaning and EDA",
    "content": "Lecture 7 – Data Cleaning and EDA Presented by Anthony D. Joseph Content by Anthony D. Joseph, Joseph Gonzalez, Deborah Nolan, Joseph Hellerstein slides video playlist code code HTML (bonus) Joe Hellerstein’s primer on data models A random one of the following Google Forms will give you an alphanumeric code once you submit; you should take this code and enter it into the “Lecture 7” question in the “Quick Check Codes” assignment on Gradescope to get credit for submitting this Quick Check. You must submit this by Monday, September 21st at 11:59PM to get credit for it. Video Quick Check 7.1 Exploratory data analysis and its position in the data science lifecycle. The relationship between data cleaning and EDA. 7.1 7.2 Exploring various different data storage formats and their tradeoffs. 7.2 7.3 Primary keys and foreign keys. Eliminating redundancy in tables. 7.3 7.4 Defining and discussing the terms quantitative discrete, quantitative continuous, qualitative ordinal, qualitative nominal. 7.4 7.5 Discussing the granularity and scope of our data to ensure that it&#39;s appropriate for analysis. Discussing various methods of encoding time, and flaws to be aware of. 7.5 7.6 Ways in which our data can be incorrect or corrupt. Different methods for addressing missing values, and their tradeoffs. 7.6 7.7 Summarizing the process of EDA. 7.7 (Optional) 7.8 A demo of EDA on real data. N/A",
    "url": "http://localhost:4000/fa20/lecture/lec07/",
    "relUrl": "/lecture/lec07/"
  },
  "11": {
    "id": "11",
    "title": "Lecture 8 – Regular Expressions",
    "content": "Lecture 8 - Regular Expressions Presented by Anthony D. Joseph Content by Anthony D. Joseph, Josh Hug slides video playlist code code HTML A random one of the following Google Forms will give you an alphanumeric code once you submit; you should take this code and enter it into the “Lecture 8” question in the “Quick Check Codes” assignment on Gradescope to get credit for submitting this Quick Check. You must submit this by Monday, September 28th at 11:59PM to get credit for it. Video Quick Check 8.1 Motivation and canonicalizing strings. 8.1 8.2 Using the split method to extract from textual data. 8.2 8.3 Basic regular expression syntax (i.e. closures). Order of operations in regular expressions. 8.3 8.4 Expanded regular expression syntax (i.e. character classes). A couple of regular expression exercises. 8.4 8.5 Limitations of regular expressions. Other regular expression syntax (i.e. lazy closures). 8.5 8.6 Using regular expressions in Python. Regular expression groups. 8.6 8.7 Regular expression case studies on police data and restaurant data. 8.7",
    "url": "http://localhost:4000/fa20/lecture/lec08/",
    "relUrl": "/lecture/lec08/"
  },
  "12": {
    "id": "12",
    "title": "Lecture 9 – Visualization, Part 1",
    "content": "Lecture 9 – Visualization, Part 1 Presented by Fernando Perez Content by Fernando Perez, Suraj Rampure, Ani Adhikari, Sam Lau, Yifan Wu slides video playlist code code HTML A random one of the following Google Forms will give you an alphanumeric code once you submit; you should take this code and enter it into the “Lecture 9” question in the “Quick Check Codes” assignment on Gradescope to get credit for submitting this Quick Check. You must submit this by Monday, September 28th at 11:59PM to get credit for it. Video Quick Check 9.1 Formal definition of visualization. The purpose of visualization in the data science lifecycle. 9.1 9.2 Different ways we can map from data to properties of a visualization. 9.2 9.3 Defining distributions, and determining whether or not given visualizations contain a distribution. 9.3 9.4 Bar plots as a means of displaying the distribution of a qualitative variable, as well as for plotting a quantitative variable across several different categories. 9.4 9.5 Rug plots. Histograms, where areas are proportions. Reviewing histogram calculations from Data 8. Density curves as smoothed versions of histograms. 9.5 9.6 Describing distributions of quantitative variables using terms such as modes, skew, tails, and outliers. 9.6 9.7 Using box plots and violin plots to visualize quantitative distributions. Using overlaid histograms and density curves, and side by side box plots and violin plots, to compare multiple quantitative distributions. 9.7 9.8 Using scatter plots, hex plots, and contour plots to visualize the relationship between pairs of quantitative variables. Summary of visualization thus far. 9.8",
    "url": "http://localhost:4000/fa20/lecture/lec09/",
    "relUrl": "/lecture/lec09/"
  },
  "13": {
    "id": "13",
    "title": "Lecture 10 – Visualization, Part 2",
    "content": "Lecture 10 – Visualization, Part 2 Presented by Fernando Perez Content by Fernando Perez, Suraj Rampure, Ani Adhikari, Sam Lau, Yifan Wu, Deborah Nolan slides video playlist code code HTML Extra reading on colormaps: matplotlib colormaps (BIDS) How the Rainbow Color Map Misleads When to use Sequential and Diverging Palettes Color Use Guidelines A random one of the following Google Forms will give you an alphanumeric code once you submit; you should take this code and enter it into the “Lecture 10” question in the “Quick Check Codes” assignment on Gradescope to get credit for submitting this Quick Check. You must submit this by Monday, October 5th at 11:59PM to get credit for it. Video Quick Check 10.1 Ensuring that the axes in our visualizations aren&#39;t misleading. 10.1 10.2 Designing visualizations that are well-suited for making comparisons. 10.2 10.3 How to use color to create effective visualizations. How to choose color schemes that are clear and accessible. 10.3 10.4 How to choose markings that the human eye can easily interpret. Issues to avoid, such as jiggling baselines and overplotting. 10.4 10.5 Discussing the supplemental text that publication-ready plots need. 10.5 10.6 When to use smoothing. How kernel density estimates are created. Looking at various kernels. Understanding the impact of the bandwidth hyperparameter. 10.6 10.7 Discussing why we prefer linear relationships. Understanding how to &quot;reverse-engineer&quot; a linearized relationship to determine the true relationship. Identifying which transformations to use in order to linearize a relationship. 10.7",
    "url": "http://localhost:4000/fa20/lecture/lec10/",
    "relUrl": "/lecture/lec10/"
  },
  "14": {
    "id": "14",
    "title": "Lecture 11 – Introduction to Modeling",
    "content": "Lecture 11 – Introduction to Modeling Presented by Fernando Perez and Suraj Rampure Content by Fernando Perez, Suraj Rampure, Ani Adhikari, Deborah Nolan, Joseph Gonzalez slides video playlist code code HTML A random one of the following Google Forms will give you an alphanumeric code once you submit; you should take this code and enter it into the “Lecture 11” question in the “Quick Check Codes” assignment on Gradescope to get credit for submitting this Quick Check. You must submit this by Monday, October 5th at 11:59PM to get credit for it. Video Quick Check 11.1 Motivating examples of models. 11.1 11.2 Defining the constant model. Formalizing the notion of a parameter. 11.2 11.3 Loss functions and their purpose. Squared loss and absolute loss. Minimizing average loss (i.e. empirical risk). 11.3 11.4 Minimizing mean squared error for the constant model using calculus, to show that the sample mean is the optimal model parameter in this case. 11.4 11.5 Performing the same optimization as in the last video, but by using a non-calculus algebraic manipulation. 11.5 11.6 Minimizing mean absolute error for the constant model using calculus, to show that the sample median is the optimal parameter in this case. Identifying that this solution isn&#39;t necessarily unique. 11.6 11.7 Comparing the loss surfaces of MSE and MAE for the constant model. Discussing the benefits and drawbacks of squared and absolute loss. Recapping the &quot;modeling process&quot;. 11.7",
    "url": "http://localhost:4000/fa20/lecture/lec11/",
    "relUrl": "/lecture/lec11/"
  },
  "15": {
    "id": "15",
    "title": "Lecture 12 – Simple Linear Regression",
    "content": "Lecture 12 – Simple Linear Regression Presented by Anthony D. Joseph and Suraj Rampure Content by Suraj Rampure and Ani Adhikari slides video playlist code code HTML A random one of the following Google Forms will give you an alphanumeric code once you submit; you should take this code and enter it into the “Lecture 12” question in the “Quick Check Codes” assignment on Gradescope to get credit for submitting this Quick Check. You must submit this by Monday, October 12th at 11:59PM to get credit for it. Video Quick Check 12.0 Introduction and recap of the modeling process. 12.0 12.1 The correlation coefficient and its properties. 12.1 12.2 Defining the simple linear regression model, our first model with two parameters and an input variable. Motivating linear regression with the graph of averages. 12.2 12.3 Using calculus to derive the optimal model parameters for the simple linear regression model, when we choose squared loss as our loss function. 12.3 12.4 Visualizing and interpreting loss surface of the SLR model. 12.4 12.5 Interpreting the slope of the simple linear model. 12.5 12.6 Defining key terminology in the regression context. Expanding the simple linear model to include any number of features. 12.6 12.7 RMSE as a metric of accuracy. Multiple R-squared as a metric of explained variation. Summary. 12.7",
    "url": "http://localhost:4000/fa20/lecture/lec12/",
    "relUrl": "/lecture/lec12/"
  },
  "16": {
    "id": "16",
    "title": "Lecture 13 – Ordinary Least Squares",
    "content": "Lecture 13 – Ordinary Least Squares Presented by Anthony D. Joseph and Suraj Rampure Content by Suraj Rampure, Ani Adhikari, Deb Nolan, Joseph Gonzalez slides video playlist code code HTML The Quick Check for this lecture is due Monday, October 12th at 11:59PM. In order to get the Gradescope submission code, you will have to follow the instructions at the end of one of these Google Forms; the instructions for this lecture are more involved as we will have you access the exam platform that we are using for the Midterm exam next week. Video Quick Check 13.1 A quick recap of the modeling process, and a roadmap for lecture. 13.1 13.2 Defining the multiple linear regression model using linear algebra (dot products and matrix multiplication). Introducing the idea of a design matrix. 13.2 13.3 Defining the mean squared error of the multiple linear regression model as the (scaled) norm of the residual vector. 13.3 13.4 Using a geometric argument to determine the optimal model parameter. 13.4 13.5 Residual plots. Properties of residuals, with and without an intercept term in our model. 13.5 13.6 Discussing the conditions in which there isn&#39;t a unique solution for the optimal model parameter. A summary, and outline of what is to come. 13.6",
    "url": "http://localhost:4000/fa20/lecture/lec13/",
    "relUrl": "/lecture/lec13/"
  },
  "17": {
    "id": "17",
    "title": "Lecture 14 – Feature Engineering",
    "content": "Lecture 14 – Feature Engineering Presented by Joseph Gonzalez Content by Joseph Gonzalez, John DeNero, Josh Hug slides video playlist code code HTML: Part 1, Part 2, Part 3 (supplementary) video and code HTML from a live lecture in Summer 2020 that reinforced some of the mathematical ideas in this lecture Important: This lecture is a combination of two lectures from previous semesters (this is why the video titles don’t match our numbering). Read this before proceeding with the lectures, as it details which concepts you should focus on. Sections 14.1 through 14.4 discuss the core techniques of feature engineering. Slides are linked above, and code is in “Part 1” and “Part 2”. 14.1: Throughout this lecture, Radial Basis Functions are used as an example. For our purposes, they are purely an example, and are not in-scope. 14.2, 14.3: Entirely in scope. 14.4: Of the three techniques discussed, one-hot encoding is most important, though the others are still in scope. Sections 14.5 through 14.7 discuss pitfalls to be aware of in feature engineering. There are no accompanying slides; these ideas are primarily explained in the lecture notebook “Part 3”. 14.5: Focus on the numerical ideas here, not the syntax of model creation (though the code is linked above). 14.6: The focus of this video is about the content at the end where our design matrix has too many columns, not about the details of Radial Basis Functions. 14.7: See the above comment. The Quick Check for this lecture is due Monday, October 26th at 11:59PM. To get credit for this lecture’s Quick Checks, you will have to fill out all of the following Google Forms as well as the mid-semester survey, linked on the course website and on Piazza (as well as in one of the following forms). Video Quick Check 14.1 A demonstration of how to use scikit-learn to fit linear models. 14.1 14.2 Feature functions, as a method of transforming existing numerical data, and encoding non-numerical data for use in modeling. 14.2 14.3 Defining what it means for a model to be linear. The constant feature. More sophisticated numerical features. 14.3 14.4 Numerically encoding categorical data using various encodings (one-hot, bag of words, n-gram). 14.4 14.5 Issues we may run into when our design matrix has redundant features. 14.5 14.6 Issues we may run into when our design matrix has more features than observations. Radial basis functions. 14.6 14.7 Overfitting our model to the data we used to train it leads to poor generalizability to unseen data, which is the goal of modeling. 14.7",
    "url": "http://localhost:4000/fa20/lecture/lec14/",
    "relUrl": "/lecture/lec14/"
  },
  "18": {
    "id": "18",
    "title": "Lecture 15 – Bias and Variance",
    "content": "Lecture 15 – Bias and Variance Presented by Fernando Perez and Ani Adhikari Content by Fernando Perez, Ani Adhikari, Suraj Rampure slides video playlist Bias-Variance decomposition derivation (raw) Important: The algebra behind the decomposition of model risk into observational variance, model variance, and bias, is not in the slides or video but is in the link above. You should read it after watching this lecture. Also, you may want to review Lecture 3 for a refresher on random variables. The Quick Check for this lecture is due Monday, October 26th at 11:59PM. A random one of the following Google Forms will give you an alphanumeric code once you submit; you should take this code and enter it into the “Lecture 15” question in the “Quick Check Codes” assignment on Gradescope to get credit for submitting this Quick Check. Video Quick Check 15.1 Variance of random variables. Walking through an alternate calculation of variance. Variance of a linear transformation. 15.1 15.2 Deriving the variance of a sum. Understanding covariance, correlation, and independence. 15.2 15.3 Variance of an i.i.d. sum. Variance of the Bernoulli and binomial distributions. 15.3 15.4 Variability of the sample mean. Reviewing inferential concepts from Data 8, but with the framework of random variables. 15.4 15.5 Introducing the data generating process and prediction error. Model risk. 15.5 15.6 Looking at different sources of error in our model – observation variance, model variance, and bias – and discussing how to mitigate them. 15.6 15.7 Decomposing model risk into the sum of observation variance, model variance, and the square of bias. 15.7",
    "url": "http://localhost:4000/fa20/lecture/lec15/",
    "relUrl": "/lecture/lec15/"
  },
  "19": {
    "id": "19",
    "title": "Lecture 16 – Cross-Validation and Regularization",
    "content": "Lecture 16 – Cross-Validation and Regularization Presented by Anthony D. Joseph, Joseph Gonzalez, Suraj Rampure, Paul Shao Content by Joseph Gonzalez, Suraj Rampure, Paul Shao slides video playlist code code HTML: Part 1, Part 2 Important: Read this before proceeding with the lectures, as it details what materials you should focus on. (This is also largely recapped in Video 16.1.) Sections 16.1 through 16.4 discuss train-test splits and cross-validation. 16.1, in addition to giving an overview of the lecture, walks through why we need to split our data into train and test in the first place, and how cross-validation works. It primarily consists of slides. 16.2 and 16.3 walk through the process of creating a basic train-test split, and evaluating models that we’ve fit on our training data using our testing data. Code is in “Part 1”. 16.4 walks through the process of implementing cross-validation. In this video there references to a Pipeline object in scikit-learn. This is not in scope for us, so do not worry about its details. Code is in “Part 1”. Sections 16.5 and 16.6 discuss regularization. 16.5 discusses why we need to regularize, and how penalties on the norm of our parameter vector accomplish this goal. 16.6 explicitly lists the optimal model parameter when using the L2 penalty on our linear model (called “ridge regression”). There are also three supplementary videos accompanying this lecture. They don’t introduce any new material, but may still be helpful for your understanding. They are listed as supplementary and not required since the runtime of this lecture is already quite long. They do not have accompanying Quick Checks for this reason. 16.7 and 16.8 walk through implementing ridge and LASSO regression in a notebook. These videos are helpful in explaining how regularization and cross-validation are used in practice. These videos again use Pipeline, which is not in scope. Code is in “Part 2”. 16.9 is another supplementary video, created by Paul Shao (a TA for Data 100 in Spring 2020). It gives a great high-level overview of both the bias-variance tradeoff and regularization. The Quick Check for this lecture is due Monday, November 2nd at 11:59PM. A random one of the following Google Forms will give you an alphanumeric code once you submit; you should take this code and enter it into the “Lecture 16” question in the “Quick Check Codes” assignment on Gradescope to get credit for submitting this Quick Check. Video Quick Check 16.1 Lecture overview. Training error vs. testing error. Why we need to split our data into train and test. How cross-validation works, and why it is useful. 16.1 16.2 Using scikit-learn to construct a train-test split. 16.2 16.3 Building a linear model and determining its training and test error. 16.3 16.4 Implementing cross-validation, and using it to help select a model. 16.4 16.5 An overview of regularization. 16.5 16.6 Ridge regression and LASSO regression. 16.6 16.7 *Supplemental.* Using ridge regression and cross-validation in scikit-learn. N/A 16.8 *Supplemental.* Using LASSO regression and cross-validation in scikit-learn. N/A 16.9 *Supplemental.* An overview of the bias-variance tradeoff, and how it interfaces with regularization. N/A",
    "url": "http://localhost:4000/fa20/lecture/lec16/",
    "relUrl": "/lecture/lec16/"
  },
  "20": {
    "id": "20",
    "title": "Lecture 17 – Gradient Descent",
    "content": "Lecture 17 – Gradient Descent Presented by Anthony D. Joseph Content by Josh Hug, Joseph Gonzalez slides video playlist code code HTML (optional) Loss Game The Quick Check for this lecture is due Monday, November 2nd at 11:59PM. A random one of the following Google Forms will give you an alphanumeric code once you submit; you should take this code and enter it into the “Lecture 17” question in the “Quick Check Codes” assignment on Gradescope to get credit for submitting this Quick Check. Video Quick Check 17.1 Gradient descent in one dimension. Convexity. 17.1 17.2 Various methods of optimizing loss functions in one dimension. 17.2 17.3 Gradient descent in multiple dimensions. Interpretation of gradients. 17.3 17.4 Stochastic gradient descent (SGD). Comparison between gradient descent and SGD. 17.4",
    "url": "http://localhost:4000/fa20/lecture/lec17/",
    "relUrl": "/lecture/lec17/"
  },
  "21": {
    "id": "21",
    "title": "Lecture 18 – Logistic Regression, Part 1",
    "content": "Lecture 18 – Logistic Regression, Part 1 Presented by Fernando Perez, Suraj Rampure Content by Suraj Rampure, Josh Hug, Joseph Gonzalez, Ani Adhikari slides video playlist code code HTML The Quick Check for this lecture is due Monday, November 9th at 11:59PM. A random one of the following Google Forms will give you an alphanumeric code once you submit; you should take this code and enter it into the “Lecture 18” question in the “Quick Check Codes” assignment on Gradescope to get credit for submitting this Quick Check. Video Quick Check 18.1 Classification, and a brief overview of the machine learning taxonomy. 18.1 18.2 Pitfalls of using least squares to model probabilities. Creating a graph of averages to motivate the logistic regression model. 18.2 18.3 Deriving the logistic regression model from the assumption that the log-odds of the probability of belonging to class 1 is linear. 18.3 18.4 Formalizing the logistic regression model. Exploring properties of the logistic function. Interpreting the model coefficients. 18.4 18.5 Discussing the pitfalls of using squared loss with logistic regression. 18.5 18.6 Introducing cross-entropy loss, as a better alternative to squared loss for logistic regression. 18.6 18.7 Using maximum likelihood estimation to arrive at cross-entropy loss. 18.7 18.8 Demo of using scikit-learn to fit a logistic regression model. An overview of what&#39;s coming next. 18.8",
    "url": "http://localhost:4000/fa20/lecture/lec18/",
    "relUrl": "/lecture/lec18/"
  },
  "22": {
    "id": "22",
    "title": "Lecture 19 – Logistic Regression Part 2, Classification",
    "content": "Lecture 19 – Logistic Regression Part 2, Classification Presented by Fernando Perez Content by Suraj Rampure, Fernando Perez, Josh Hug, Joseph Gonzalez, Ani Adhikari slides video playlist code code HTML (supplementary) video on cross-entropy loss and KL divergence The Quick Check for this lecture is due Monday, November 16th at 11:59PM. A random one of the following Google Forms will give you an alphanumeric code once you submit; you should take this code and enter it into the “Lecture 19” question in the “Quick Check Codes” assignment on Gradescope to get credit for submitting this Quick Check. Video Quick Check 19.1 Using thresholds to convert from predicted probabilities to classifications. 19.1 19.2 Defining several metrics of classifier performance – accuracy, precision, and recall. Confusion matrices. 19.2 19.3 Using scikit-learn to compute accuracy, precision, recall, and confusion matrices. 19.3 19.4 Exploring how threshold impacts accuracy, precision, and recall. Precision-recall curves. ROC curves. AUC. 19.4 19.5 Exploring the decision boundaries that result from a logistic regression classifier, and their relationship to the model&#39;s parameters. 19.5 19.6 Linear separability. Why we sometimes need regularization for logistic regression. 19.6 19.7 Summary. Brief introduction to multiclass classification. N/A",
    "url": "http://localhost:4000/fa20/lecture/lec19/",
    "relUrl": "/lecture/lec19/"
  },
  "23": {
    "id": "23",
    "title": "Lecture 20 – Decision Trees",
    "content": "Lecture 20 – Decision Trees Presented by Anthony D. Joseph Content by Josh Hug slides video playlist code code HTML The Quick Check for this lecture is due Monday, November 16th at 11:59PM. A random one of the following Google Forms will give you an alphanumeric code once you submit; you should take this code and enter it into the “Lecture 20” question in the “Quick Check Codes” assignment on Gradescope to get credit for submitting this Quick Check. Video Quick Check 20.1 Decision tree basics. Decision trees in scikit-learn. 20.1 20.2 Overfitting and decision trees. 20.2 20.3 Decision tree generation. Finding the best split. Entropy and weighted entropy. 20.3 20.4 Restricting decision tree complexity. Preventing growth and pruning. Random forests and bagging. 20.4 20.5 Regression trees. Summary of decision trees, classification, and regression. 20.5",
    "url": "http://localhost:4000/fa20/lecture/lec20/",
    "relUrl": "/lecture/lec20/"
  },
  "24": {
    "id": "24",
    "title": "Lecture 21 – Inference for Modeling",
    "content": "Lecture 21 – Inference for Modeling Presented by Fernando Perez and Suraj Rampure Content by Suraj Rampure, Fernando Perez, John DeNero, Sam Lau, Ani Adhikari, Deb Nolan slides video playlist code code HTML The Data 8 textbook chapter on estimation may be very helpful. The Quick Check for this lecture is due Monday, November 23rd at 11:59PM. A random one of the following Google Forms will give you an alphanumeric code once you submit; you should take this code and enter it into the “Lecture 21” question in the “Quick Check Codes” assignment on Gradescope to get credit for submitting this Quick Check. Video Quick Check 21.1 A big picture overview of inference. Parameters and estimators. Bias and variance of estimators. The sample mean estimator. 21.1 21.2 Using bootstrap resampling in order to estimate the sampling distribution of an estimator. 21.2 21.3 Defining confidence intervals more generally. Describing and demoing how we can use the bootstrap to create confidence intervals for population parameters. 21.3 21.4 The assumptions we make when modeling with linear regression.. 21.4 21.5 Using the bootstrap to estimate the sampling distributions of parameters in a linear regression model. Inference for the true slope of a feature. 21.5 21.6 Multicollinearity, and its impacts on the interpretability of the parameters of our model. A summary of the lecture, and a brief overview of the ML taxonomy. 21.6",
    "url": "http://localhost:4000/fa20/lecture/lec21/",
    "relUrl": "/lecture/lec21/"
  },
  "25": {
    "id": "25",
    "title": "Lecture 22 – Principal Components Analysis",
    "content": "Lecture 22 – Principal Components Analysis Presented by Anthony D. Joseph Content by Josh Hug, John DeNero, Sam Lau, and Suraj Rampure slides video playlist code code HTML Summer 2020 notes on PCA (Optional) PCA tutorial The Quick Check for this lecture is due Monday, November 23rd at 11:59PM. A random one of the following Google Forms will give you an alphanumeric code once you submit; you should take this code and enter it into the “Lecture 22” question in the “Quick Check Codes” assignment on Gradescope to get credit for submitting this Quick Check. Video Quick Check 22.1 Dimensionality. Visualizing high-dimensional data. 22.1 22.2 More visualizations of high-dimensional data. 22.2 22.3 Matrix decomposition, redundancy, and rank. Introduction to the singular value decomposition (SVD). 22.3 22.4 The theory behind the singular value decomposition. Orthogonality and orthonormality. 22.4 22.5 Definition and computation of principal components. Geometric interpretation of principal components and low rank approximations. Data centering. 22.5 22.6 Interpretation of singular values. The relationship between singular values and variance. Analyzing scree plots. 22.6 22.7 Introduction to principal Component analysis (PCA). PCA for exploratory data analysis. 22.7",
    "url": "http://localhost:4000/fa20/lecture/lec22/",
    "relUrl": "/lecture/lec22/"
  },
  "26": {
    "id": "26",
    "title": "Lecture 23 – Clustering",
    "content": "Lecture 23 – Clustering Presented by Anthony D. Joseph Content by Josh Hug slides video playlist code code HTML The Quick Check for this lecture is due Monday, November 30th at 11:59PM. A random one of the following Google Forms will give you an alphanumeric code once you submit; you should take this code and enter it into the “Lecture 23” question in the “Quick Check Codes” assignment on Gradescope to get credit for submitting this Quick Check. Video Quick Check 23.1 Introduction to clustering. Examples of clustering in practice. 23.1 23.2 The K-Means clustering algorithm. Example of K-Means clustering. 23.2 23.3 Loss functions for K-Means. Inertia and distortion. Optimizing inertia. 23.3 23.4 Agglomerative clustering as an alternative to K-Means. Example of agglomerative clustering. Dendrograms and other clustering algorithms. 23.4 23.5 Picking the number of clusters. The elbow method and silhouette scores. Summary of clustering and machine learning. 23.5",
    "url": "http://localhost:4000/fa20/lecture/lec23/",
    "relUrl": "/lecture/lec23/"
  },
  "27": {
    "id": "27",
    "title": "Lecture 24 – Big Data",
    "content": "Lecture 24 – Big Data Presented by Anthony D. Joseph Content by Anthony D. Joseph, Joseph Gonzalez, Josh Hug slides video playlist The Quick Check for this lecture is due Monday, December 7th at 11:59PM. A random one of the following Google Forms will give you an alphanumeric code once you submit; you should take this code and enter it into the “Lecture 24” question in the “Quick Check Codes” assignment on Gradescope to get credit for submitting this Quick Check. Video Quick Check 24.1 An overview of big data, with several pertinent examples. Operational data stores and data warehouses. Extract, transform, load (ETL). 24.1 24.2 The multidimensional data model. Fact tables and dimension tables. Star schemas and snowflake schemas. Online analytics processing (OLAP). 24.2 24.3 Data warehouses and data lakes. 24.3 24.4 Distributed file systems and fault tolerance. 24.4 24.5 Distributed aggregation with MapReduce. The MapReduce abstraction. 24.5 24.6 Hadoop and Spark. Resilient Distributed Datasets (RDDs). Modin. 24.6",
    "url": "http://localhost:4000/fa20/lecture/lec24/",
    "relUrl": "/lecture/lec24/"
  },
  "28": {
    "id": "28",
    "title": "Resources",
    "content": "Resources Exam Resources Semester Midterm (1) Midterm 2 Final Fall 2020 Exam (Solutions)     Summer 2020 Exam (Solutions) Exam (Solutions) Exam (Solutions) Spring 2020 Checkpoint (Solutions)   N/A Fall 2019 Exam (Solutions) Exam (Solutions) Exam (Solutions) Summer 2019 Exam (Solutions) [Video]   Exam (Solutions) Spring 2019 Exam (Solutions) [Video] Exam (Solutions) [Video] Exam (Solutions) Fall 2018 Exam (Solutions)   Exam (Solutions) Spring 2018 Exam (Solutions)   Exam (Solutions) [Video] Fall 2017 Exam (Solutions) [Video]   Exam (Solutions) Spring 2017 Exam (Solutions)   Exam (Solutions) Spring 2020 Checkpoint Reference Sheet Fall 2019 Midterm 1 Reference Sheet Spring 2019 Midterm 1 Reference Sheet Other Resources We will be posting all lecture materials on the course syllabus. In addition, they will also be listed in the following publicly visible Github Repo. Here is a collection of resources that will help you learn more about various concepts and skills covered in the class. Learning by reading is a key part of being a well rounded data scientist. We will not assign mandatory reading but instead encourage you to look at these and other materials. If you find something helpful, post it on Piazza, and consider contributing it to the course website. You can send us changes to the course website by forking and sending a pull request to the course website github repository. You will then become part of the history of Data 100 at Berkeley. Local Setup Click here to read our guide on how to set up our development environment locally (as an alternative to using DataHub). SQL Resources We’ve assembled some SQL Review Slides to help you brush up on SQL. We’ve also compiled a list of SQL practice problems, which can be found here, along with their solutions. This SQL Cheat Sheet is an awesome resource that was created by Luke Harrison, a former Data 100 student. Probability Practice We’ve compiled a few practice probability problems that we believe may help in understanding the ideas covered in the course. They can be found here, along with their solutions. We’d also like to point you to the textbook for Stat 88, an introductory probability course geared towards data science students at Berkeley. Regex Practice We’ve organized some regex problems to help you get extra practice on regex in a notebook format. They can be found here, along with their solutions. Web References As a data scientist you will often need to search for information on various libraries and tools. In this class we will be using several key python libraries. Here are their documentation pages: The Bash Command Line: Linux and Bash: Intro to Linux, Cloud Computing (which you can skip for the purposes of this class), and the Bash command line. You can skip all portions that don’t pertain to using the command line. Bash Part 2: Part 2 of the intro to command line. Python: Python Tutorial: Teach yourself python. This is a pretty comprehensive tutorial. Python + Numpy Tutorial this tutorial provides a great overview of a lot of the functionality we will be using in DS100. Python 101: A notebook demonstrating a lot of python functionality with some (minimal explanation). Data Visualization: matplotlib.pyplot tutorial: This short tutorial provides an overview of the basic plotting utilities we will be using. Altair Documentation: Altair(Vega-Lite) is a new and powerful visualization library. We might not get to teach it this semester, but you should check it out if you are interested in pursuing visualization deeper. In particular, you should find the example gallery helpful. Prof. Jeff Heer’s Visualization Curriculum: This repository contains a series of Python-based Jupyter notebooks that teaches data visualization using Vega-Lite and Altair. If you are interested in learning more about data visualization, you can find more materials in: Edward Tufte’s book sequences – a classic! Prof. Heer’s class. Pandas: The Pandas Cookbook: This provides a nice overview of some of the basic Pandas functions. However, it is slightly out of date. Learn Pandas A set of lessons providing an overview of the Pandas library. Python for Data Science Another set of notebook demonstrating Pandas functionality. Books Because data science is a relatively new and rapidly evolving discipline there is no single ideal textbook for this subject. Instead we plan to use reading from a collection of books all of which are free. However, we have listed a few optional books that will provide additional context for those who are interested. Principles and Techniques of Data Science This is the accompanying textbook written for DS100 course. Introduction to Statistical Learning (Free online PDF) This book is a great reference for the machine learning and some of the statistics material in the class Data Science from Scratch (Available as eBook for Berkeley students) This more applied book covers many of the topics in this class using Python but doesn’t go into sufficient depth for some of the more mathematical material. Doing Data Science (Available as eBook for Berkeley students) This books provides a unique case-study view of data science but uses R and not Python. Python for Data Analysis (Available as eBook for Berkeley students). This book provides a good reference for the Pandas library. Data Science Education Interested in bringing the Data Science major or curriculum to your academic institution? Please fill out this form if you would like support from Berkeley in offering some variant of our Data Science courses at your institution (or just to let us know that you’re interested). Information about the courses appear at data8.org and ds100.org. Please note that this form is for instructors. If you are only interested in learning Python or data science, please look at our Data 8 or Data 100 websites mentioned above.",
    "url": "http://localhost:4000/fa20/resources/",
    "relUrl": "/resources/"
  },
  "29": {
    "id": "29",
    "title": "Local Setup",
    "content": "Local Setup We will still be using datahub as our primary computing environment. This page serves as a guide for alternative environment setup. In other words: you don’t have to follow these instructions unless you’d like an alternative to datahub. Contents Installing conda by OS OSX Windows Linux Creating your environment Working on assignments locally Opening notebooks locally Verifying your environment Removing the environment to start over Submitting your work FAQ OSX You will need access to the command line. On a Mac, you can open the Terminal by opening Spotlight (Cmd + Space) and typing &quot;Terminal&quot;. Alternatively, you can go to your Applications screen and select Terminal (it might be in the folder named &quot;Other&quot;) Homebrew is a package manager for OSX. If you haven’t already, install it by running the following in the command line (copy, paste, and enter): # This downloads the Ruby code of the installation script and runs it /usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; Verify your installation by making sure brew --version doesn’t error at your terminal. Download and install Anaconda: # Uses curl to download the installation script curl https://repo.continuum.io/miniconda/Miniconda2-4.5.11-MacOSX-x86_64.sh &gt; miniconda.sh # Run the miniconda installer (you will need to enter your password) bash miniconda.sh Close and restart your terminal. Ensure the installation worked by running conda --version. You may remove the miniconda.sh script now if you’d like. Click here to continue to the next part of the setup. Windows Windows is especially prone to error if you aren’t careful about your configuration. If you’ve already had Anaconda or git installed and can’t get the other to work, try uninstalling everything and starting from scratch. Installing Anaconda: Visit the Anaconda website and download the installer for Python 3.7. Download the 64-bit installer if your computer is 64-bit (most likely), the 32-bit installer if not. See this FAQ if you are unsure. Run the exe file to install Anaconda. Leave all the options as default (install for all users, in the default location). Make sure both of these checkboxes are checked: 1) Verify that the installation is working by starting the Anaconda Prompt (you should be able to start it from the Start Menu) and typing python: Notice how the python prompt shows that it is running from Anaconda. Now you have conda installed! From now on, when we talk about the “Terminal” or “Command Prompt”, we are referring to the Anaconda Prompt that you just installed. Click here to continue to the next part of the setup. Linux These instructions assume you have apt-get (Ubuntu and Debian). For other distributions of Linux, substitute the appropriate package manager. Your terminal program allows you to type commands to control your computer. On Linux, you can open the Terminal by going to the Applications menu and clicking “Terminal”. Install wget. This is a command-line tool that lets you download files / webpages at the command line. sudo apt-get install wget Download the Anaconda installation script: wget -O install_anaconda.sh https://repo.continuum.io/miniconda/Miniconda2-4.5.11-Linux-x86_64.sh 4) Install Anaconda: bash install_anaconda.sh 5) Close and restart your terminal. Ensure the installation worked by running `conda --version`. You may remove the install_anaconda.sh script now if you’d like. Click here to continue to the next part of the setup. Creating your environment These instructions are the same for OSX, Windows, and Linux. Download the data100 data100_environment.yml] from the course repository here or: # download via curl curl https://raw.githubusercontent.com/DS-100/su20/gh-pages/resources/assets/local_setup/data100_environment.yml &gt; data100_environment.yml # OR download via wget wget -O data100_environment.yml https://raw.githubusercontent.com/DS-100/su20/gh-pages/resources/assets/local_setup/data100_environment.yml This YAML file is what we use to specify the dependencies and packages (and their versions) we wish to install into the conda environment we will make for this class. The purpose of the environment is to ensure that everyone in the course is using the same package versions for every assignment whether or not they are working on datahub. This is to prevent inconsistent behavior due to differences in package versions. Using the Terminal, navigate to the directory where you downloaded data100_environment.yml. Run these commands to create a new conda environment. Each conda environment maintains its own package versions, allowing us to switch between package versions easily. For example, this class uses Python 3, but you might have another that uses Python 2. With a conda environment, you can switch between those at will. # sanity check on conda installation. Should be 4.5 or higher conda --version # update conda just in case it&#39;s out of date # enter y if prompted to proceed conda update conda # download git conda install -c anaconda git # Create a python 3.6 conda environment with the full set # of packages specified in environment.yml (jupyter, numpy, pandas, ...) conda env create -f data100_environment.yml # Switch to the data100 environment conda activate data100 # Check if packages are in the environment # This should not be empty! conda list From now on, you can switch to the data100 env with conda activate data100, and switch back to the default env with conda deactivate. Working on assignments locally These instructions are the same for OSX, Windows, and Linux. To work on assignments, you should fetch the assignment on datahub, navigate to the assignment folder and click on the download icon on the top right: Then you can unzip the files into a folder of your choosing. Remember the location of your assignment files because you’ll need to navigate to that folder to open the notebook. Opening notebooks locally To open Jupyter notebooks, you’ll navigate to parent directory of the assignment in your terminal, activate the environment, and start up a jupyter server. This will look something like: cd path/to/assignment/directory conda activate data100 jupyter notebook This will automatically open the notebook interface in your browser. You can then browse to a notebook and open it. Make sure to always work in the data100 conda environment when you are using jupyter notebooks for this class. This ensures you have all the necessary packages required for the notebook to run. Verifying Your Environment You can tell if you are correct environment if your terminal looks something like: Additionally, conda env list outputs a list of all your conda environments, and data100 should appear with a * next to it (the active one). Removing the environment to start over If you feel as if you’ve messed up and need to start over, you can remove the environment with conda remove --name data100 --all To verify that the environment was removed, in your Terminal window or an Anaconda Prompt, run: conda info --envs Which should then no longer display the data100 environment. Submitting your work Submissions will still be handled via datahub. To upload your work, navigate to the appropriate assignment folder on datahub and click on the upload button on the top right. Remember to validate, submit, and upload to Gradescope (for homeworks and projects). FAQ Shell not properly configured to use conda activate If you had an older version of Anaconda installed (perhaps for another class), you may see the following message. Follow the instructions in the prompt to: Enable conda for all users sudo ln -s ... Put the base environment on PATH echo &quot;conda activate&quot; &gt;&gt; ~/.bash_profile&quot;. Note that ~/.bash_profile may be something different like ~/.bashrc. Manually remove the line that looks like export PATH=&quot;/usr/local/miniconda3/bin:$PATH&quot; from your .bash_profile. Use your favorite plaintext editor to do this (do not use a rich text editor like Microsoft Word!).",
    "url": "http://localhost:4000/fa20/setup/",
    "relUrl": "/setup/"
  },
  "30": {
    "id": "30",
    "title": "Staff",
    "content": "Staff Jump to Instructors, Teaching Assistants, or Tutors Note: Consult the calendar for the most up-to-date office hours for each GSI. Instructors {% assign instructors = site.staffers | where: &#39;role&#39;, &#39;Instructor&#39; %} {% for staffer in instructors %} {{ staffer }} {% endfor %} Teaching Assistants {% assign teaching_assistants = site.staffers | where: &#39;role&#39;, &#39;Teaching Assistant&#39; %} {% for staffer in teaching_assistants %} {{ staffer }} {% endfor %} Tutors {% assign readers = site.staffers | where: &#39;role&#39;, &#39;Tutor&#39; %} {% for staffer in readers %} {{ staffer }} {% endfor %}",
    "url": "http://localhost:4000/fa20/staff/",
    "relUrl": "/staff/"
  },
  "31": {
    "id": "31",
    "title": "Syllabus",
    "content": "Syllabus Jump to: About Data 100 Online Format Policies About Data 100 Combining data, computation, and inferential thinking, data science is redefining how people and organizations solve challenging problems and understand their world. This intermediate level class bridges between Data8 and upper division computer science and statistics courses as well as methods courses in other fields. In this class, we explore key areas of data science including question formulation, data collection and cleaning, visualization, statistical inference, predictive modeling, and decision making.​ Through a strong emphasis on data centric computing, quantitative critical thinking, and exploratory data analysis, this class covers key principles and techniques of data science. These include languages for transforming, querying and analyzing data; algorithms for machine learning methods including regression, classification and clustering; principles behind creating informative data visualizations; statistical concepts of measurement error and prediction; and techniques for scalable data processing. Goals Prepare students for advanced Berkeley courses in data-management, machine learning, and statistics, by providing the necessary foundation and context Enable students to start careers as data scientists by providing experience working with real-world data, tools, and techniques Empower students to apply computational and inferential thinking to address real-world problems Prerequisites While we are working to make this class widely accessible, we currently require the following (or equivalent) prerequisites. We are not enforcing prerequisites during enrollment. However, all of the prerequisties will be used starting very early on in the class. It is your responsibility to know the material in the prerequisites.: Foundations of Data Science: Data8 covers much of the material in Data 100 but at an introductory level. Data8 provides basic exposure to python programming and working with tabular data as well as visualization, statistics, and machine learning. Computing: The Structure and Interpretation of Computer Programs (CS 61A) or Computational Structures in Data Science (CS 88). These courses provide additional background in python programming (e.g., for loops, lambdas, debugging, and complexity) that will enable Data 100 to focus more on the concepts in Data Science and less on the details of programming in python. Math: Linear Algebra (Math 54, EE 16a, or Stat89a): We will need some basic concepts like linear operators, eigenvectors, derivatives, and integrals to enable statistical inference and derive new prediction algorithms. This may be satisfied concurrently to Data 100. Online Format This fall, Data 100 will be run entirely online. This section details exactly how each component of the course will operate. But here’s a nice high-level “typical week in the course”: Monday Tuesday Wednesday Thursday Friday Office Hours Office Hours Office Hours Office Hours Office Hours Live lab Lecture released Discussion Lecture released Homework released Lab due, Quick Check due     Homework due Lab released Note that these deadlines are subject to change. To see when any live events are scheduled, check the Calendar. To see when lectures, discussions, and assignments are released (and due), check the Home Page. Lecture There are 2 lectures per week. Lectures will be entirely pre-recorded, in a format that is optimized for online learning (short 5-10 minute videos with conceptual problems in between). Lecture videos will be released on the mornings of Tuesday and Thursday. Some of these will be from previous semesters, and some will be recorded this fall by the instructors. Lecture videos will be posted on YouTube. Each “lecture” will be an html page linked on the course website, containing videos and links to slides and code. There are “Quick Check” conceptual questions in between each lecture video, linked on the lecture webpage. See below for more details. Each lecture will also have a Piazza thread for students to ask questions. Note: Alongside each lecture are textbook readings. Textbook readings are purely supplementary, and may contain material that is not in scope (and may also not be comprehensive). Quick Checks Quick Checks, as mentioned above, are short conceptual questions embedded into each lecture, in the form of Google Forms. These are meant for you to check your understanding of the concepts that were just introduced. Since there are roughly 26 lectures, there are roughly 26 Quick Checks, each of which consists of 4-7 Google Forms. Quick Checks are graded on completion. That is, your score on them does not matter, you just need to do them. For each lecture, you will be required to submit a code to Gradescope that you will receive after completing one of the Google Forms for that lecture. These are due the Monday after the lecture is released. (Though we will assign grades using Gradescope, we will also collect emails on the Google Forms themselves.) Homeworks and Projects Homeworks are week-long assignments that are designed to help students develop an in-depth understanding of both the theoretical and practical aspects of ideas presented in lecture. Projects are two-week-long assignments that integrate these ideas with real-world datasets. In a typical week, homework is released on Friday and is due the following Thursday at 11:59PM. Near the midterm, or during weeks in which a project is assigned, you will have more than one week to work on the current assignment. One or two homeworks will be on-paper written assignments; the rest will be Jupyter notebooks. Homeworks have both visible and hidden autograder tests. The visible tests are mainly sanity checks, e.g. a probability is &lt;= 1, and are visible to students while they do the assignment. The hidden tests generally check for correctness, and are invisible to students while they are doing the assignment. The primary form of support students will have for homeworks and projects are the office hours we’ll host, and Piazza. Homeworks must be completed individually. Labs Labs are shorter programming assignments designed to give students familiarity with new ideas. In a typical week, lab is released on Friday and is due the following Monday. All lab autograder tests are visible. To help with lab, we will host live lab sections on Monday at various times, in which GSIs will walk through the assignment via Zoom. See the Calendar for when these are scheduled. Students can also get help with labs at office hours and on Piazza. Discussions Discussion sections are meant to allow students a chance to discuss conceptual ideas and solve problems with other students, with the help of a GSI (this becomes slightly harder given the fact that this course is being offered completely remotely). Each discussion consists of a worksheet. In a typical week, we will release the discussion worksheet on Wednesday morning. There are two “pathways” we envision students taking when it comes to consuming discussion content. Watching a pre-recorded discussion video. Each discussion worksheet will be accompanied with a GSI-created video walkthrough, released at the same time. Students should watch this video soon after it is released. With any lingering questions, students should come to office hours. Coming to a live Zoom discussion section. We will be holding live discussion sections at several times on Wednesdays. In the first few weeks, students will be able to attend whichever section they desire, but we will eventually require you to sign up for a particular section if you want to keep attending (this is to keep sections small and personal). Office Hours We plan on hosting roughly 10 hours of office hours each weekday. These hours are listed on the Calendar. OH will serve as a one-stop shop for students to get help with assignments. Office Hours can be accessed via oh.ds100.org, where students add themselves to the “queue” and specify the assignment they need help on. Once it’s their turn, they will be provided with a Zoom link to join, in order to get help from staff. The instructors will also be hosting conceptual office hours. These will be reflected on the Calendar. We are also holding “lost office hours” once a week. These are designed to accommodate students who are behind on material and would like help catching up. These are meant for conceptual questions only, not for assignment help. These will also be reflected on the Calendar. Exams There will be one midterm exam, on October 15th (7-9PM PDT), and a final exam on December 15th (7-10PM PST). Alternate exams will only be given to students with a documented conflict, or to those who are in timezones very far from Pacific Time, or to those who have extenuating circumstances. Policies Undergraduate Grading Scheme (for students enrolled in Data C100): Category Weight Details Homeworks 30% 8, with 2 drops Labs 10% 13, with 3 drops Projects 15% 7.5% each (2, with 0 drops) Quick Checks 5%   Midterm Exam 15%   Final 25%   Graduate Grading Scheme (for students enrolled in Data C200): Category Weight Details Homeworks 30% 8, with 2 drops Projects 15% 7.5% each (2, with 0 drops) Final Project 15%   Midterm Exam 15%   Final 25%   Note that a ninth homework and second homework drop were announced partway through the semester. Late Policy All assignments are due at 11:59 pm on the due date specified on the syllabus. Gradescope is where all assignments are submitted. Extensions are only provided to students with DSP accommodations, or in the case of exceptional circumstances. Homeworks and labs will not be accepted late. Gradescope may allow you to make late submissions, but you will later be given a 0. Projects are marked down by 10% per day, up to two days. After two days, project submissions will not be accepted. Submission times are rounded up to the next day. That is, 2 minutes late = 1 day late. Collaboration Policy and Academic Dishonesty Assignments Data science is a collaborative activity. While you may talk with others about the homework, we ask that you write your solutions individually in your own words. If you do discuss the assignments with others please include their names at the top of your notebook. Keep in mind that content from assignments will likely be covered on both the midterm and final. If we suspect that you have submitted plagiarized work, we will call you in for a meeting. If we then determine that plagiarism has occurred, we reserve the right to give you a negative full score (-100%) or lower on the assignments in question, along with reporting your offense to the Center of Student Conduct. Rather than copying someone else’s work, ask for help. You are not alone in this course! The entire staff is here to help you succeed. If you invest the time to learn the material and complete the assignments, you won’t need to copy any answers. (taken from 61A) We also ask that you do not post your assignment solutions publicly. Exams Cheating on exams is a serious offense. We have methods of detecting cheating on exams – so don’t do it! Students caught cheating on any exam will fail this course. We will be following the EECS departmental policy on Academic Honesty, so be sure you are familiar with it. We want you to succeed! If you are feeling overwhelmed, visit our office hours and talk with us. We know college can be stressful – and especially so during the COVID-19 pandemic – and we want to help you succeed.",
    "url": "http://localhost:4000/fa20/syllabus/",
    "relUrl": "/syllabus/"
  }
  
}
