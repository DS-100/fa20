---
layout: page
title: Lecture 12 – Simple Linear Regression
nav_exclude: true
---

# Lecture 12 – Simple Linear Regression

Presented by Anthony D. Joseph and Suraj Rampure

Content by Suraj Rampure and Ani Adhikari

- [slides](https://docs.google.com/presentation/d/1rHflVaF3aTMD7h96Bv0cwTkbrCTo5xNVq_dfOL7dpCE/edit?usp=sharing)
- [video playlist](https://www.youtube.com/playlist?list=PLQCcNQgUcDfqagPht9n4nHN9-aV784R3c)
- [code](https://data100.datahub.berkeley.edu/hub/user-redirect/git-sync?repo=https://github.com/DS-100/fa20&subPath=lecture/lec12/)
- [code HTML](../../resources/assets/lectures/lec12/lec12.html)

Make sure to complete the Quick Check questions in between each video. These are ungraded, but it's in your best interest to do them.

<table>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Video</th>
<th>Quick Check</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>12.0</strong> <br>Introduction and recap of the modeling process.</td>
<td><iframe width="300" height="300" height src="https://youtube.com/embed/TXWx4v5MGm8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
<td><a href="https://docs.google.com/forms/d/e/1FAIpQLSd5Z75WksSVQqVjoqfLVaKpiVrvNgjyNEuDsGOmgLlEhASaMg/viewform" target="\_blank">12.0</a></td>
</tr>
<tr>
<td><strong>12.1</strong> <br>The correlation coefficient and its properties.</td>
<td><iframe width="300" height="300" height src="https://youtube.com/embed/vo9ey0DL1nk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
<td><a href="https://docs.google.com/forms/d/e/1FAIpQLSfMaP_29_Az1FQgvGBtdQ8AfcqbhmUJazaqBIKLQtVSRnT0dQ/viewform" target="\_blank">12.1</a></td>
</tr>
<tr>
<td><strong>12.2</strong> <br>Defining the simple linear regression model, our first model with two parameters and an input variable. Motivating linear regression with the graph of averages.</td>
<td><iframe width="300" height="300" height src="https://youtube.com/embed/crDa6Y34r3A" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
<td><a href="https://docs.google.com/forms/d/e/1FAIpQLSeTZE25q_9AFN2tO5kEAnp6IPv3JpOVv6orKeNV0Jxpvpt9iw/viewform" target="\_blank">12.2</a></td>
</tr>
<tr>
<td><strong>12.3</strong> <br>Using calculus to derive the optimal model parameters for the simple linear regression model, when we choose squared loss as our loss function.</td>
<td><iframe width="300" height="500" height src="https://youtube.com/embed/7hVK78Ir618" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
<td><a href="https://docs.google.com/forms/d/e/1FAIpQLSeY0yhl9hQRZmxlMe42kvE5pbGJHwyjoTOp-BPJZNiRJTt-Cg/viewform" target="\_blank">12.3</a></td>
</tr>
<tr>
<td><strong>12.4</strong> <br>Visualizing and interpreting loss surface of the SLR model.</td>
<td><iframe width="300" height="300" height src="https://youtube.com/embed/K3e19T_Z9JU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
<td><a href="https://docs.google.com/forms/d/e/1FAIpQLSemBu1vJ5j_uoPzLqSGCDh-4GBGRf-M4mW-vXjweMMlAtGrpQ/viewform" target="\_blank">12.4</a></td>
</tr>
<tr>
<td><strong>12.5</strong> <br>Interpreting the slope of the simple linear model. </td>
<td><iframe width="300" height="300" height src="https://youtube.com/embed/dKI_lDXDzvI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
<td><a href="https://docs.google.com/forms/d/e/1FAIpQLSfNAMYYJxNWFJlpz3Wl7Xa2jEMalnBw6FLsjr2ukcjDZ1XM_g/viewform" target="\_blank">12.5</a></td>
</tr>
<tr>
<td><strong>12.6</strong> <br>Defining key terminology in the regression context. Expanding the simple linear model to include any number of features.</td>
<td><iframe width="300" height="300" height src="https://youtube.com/embed/LHbuY63Bh_0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
<td><a href="https://docs.google.com/forms/d/e/1FAIpQLSfb77dDmoZlrkdQH3ocSFw1xr-_YQdYg1hRZv2oUrxUcaf8Lw/viewform" target="\_blank">12.6</a></td>
</tr>
<tr>
<td><strong>12.7</strong> <br>RMSE as a metric of accuracy. Multiple R-squared as a metric of explained variation. Summary.</td>
<td><iframe width="300" height="300" height src="https://youtube.com/embed/1jLglngUYUM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
<td><a href="https://docs.google.com/forms/d/e/1FAIpQLScZ40zJtTzCPhjZf-V4op0lgujVp__HNlAIKKkHi95aYq_Ejg/viewform" target="\_blank">12.7</a></td>
</tr>
