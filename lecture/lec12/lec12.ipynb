{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 12 â€“ Simple Linear Regression\n",
    "\n",
    "**by Suraj Rampure**\n",
    "\n",
    "Notebook credits:\n",
    "- Ani Adhikari\n",
    "- Data 8's textbook, chapter 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's come up with some examples of data to use in slides. (Normally this wouldn't be put in the notebook, but it might be of interest to you.)\n",
    "\n",
    "Also, note here we use `np.corrcoef` here to compute the correlation coefficients, because we haven't yet defined what `r` is manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just noise\n",
    "np.random.seed(43)\n",
    "plt.figure(figsize = (4, 4))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3)\n",
    "x1, y1 = np.random.randn(2, 100)\n",
    "plt.scatter(x1, y1, alpha = 0.75);\n",
    "# plt.savefig('images/s1.png')\n",
    "print(np.corrcoef(x1, y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strong linear\n",
    "np.random.seed(43)\n",
    "plt.figure(figsize = (4, 4))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3)\n",
    "x2 = np.linspace(-3, 3, 100)\n",
    "y2 = x2*0.5 - 1 + np.random.randn(100)*0.3\n",
    "plt.scatter(x2, y2, alpha = 0.75);\n",
    "# plt.savefig('images/s2.png')\n",
    "print(np.corrcoef(x2, y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strong non-linear\n",
    "np.random.seed(43)\n",
    "plt.figure(figsize = (4, 4))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3)\n",
    "x3 = np.linspace(-3, 3, 100)\n",
    "y3 = 2*np.sin(x3 - 1.5) + np.random.randn(100)*0.3\n",
    "plt.scatter(x3, y3, alpha = 0.75);\n",
    "# plt.savefig('images/s3.png')\n",
    "print(np.corrcoef(x3, y3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unequal spread\n",
    "np.random.seed(43)\n",
    "plt.figure(figsize = (4, 4))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3)\n",
    "x4 = np.linspace(-3, 3, 100)\n",
    "y4 = x4/3 + np.random.randn(100)*(x4)/2.5\n",
    "plt.scatter(x4, y4, alpha = 0.75);\n",
    "# plt.savefig('images/s4.png')\n",
    "print(np.corrcoef(x4, y4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's implement the tools we'll need for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_units(x):\n",
    "    return (x - np.mean(x)) / np.std(x)\n",
    "\n",
    "def correlation(x, y):\n",
    "    return np.mean(standard_units(x) * standard_units(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('galton.csv').iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting issue is that both our `parent` and `child` columns occur at fixed positions. We need to add some random noise, otherwise we'll suffer from gross overplotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['parent'] = df['parent'] + np.random.randn(len(df))/2\n",
    "df['child'] = df['child'] + np.random.randn(len(df))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df, x= 'parent', y = 'child')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our `correlation` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(df['parent'], df['child'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using an in-built `correlation` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df['parent'], df['child'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the same result.\n",
    "\n",
    "What we now want to do is compute the **average $y$ for a given $x$**. A practical way to do this is to \"bin\" our x axis into 1-unit wide buckets, and then compute the average $y$ value for everything in that bucket. (We could choose bins of any width, though.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mean_y(x):\n",
    "    return df.loc[np.abs(df['parent'] - x) <= 0.5, 'child'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['child_predicted'] = df['parent'].apply(predict_mean_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at our predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x = df['parent'], y = df['child'], mode = 'markers', name = 'actual'))\n",
    "fig.add_trace(go.Scatter(x = df['parent'], y = df['child_predicted'], mode = 'markers', name = 'predicted means', line=dict(color='gold')))\n",
    "fig.update_layout(xaxis_title = 'MidParent Height', yaxis_title = 'Child Height')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save for the tails where there are fewer values to draw from, it seems like our red predictions roughly follow a straight line piercing through the \"middle\" of our point cloud. That's our motivation for using a line to model this bivariate data.\n",
    "\n",
    "Note: The cool thing about plotly is that you can hover over the points and it will tell you whether it is a prediction or actual value.\n",
    "\n",
    "Now, it's time to implement the optimal coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope(x, y):\n",
    "    return correlation(x, y) * np.std(y) / np.std(x)\n",
    "\n",
    "def intercept(x, y):\n",
    "    return np.mean(y) - slope(x, y)*np.mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahat = intercept(df['parent'], df['child'])\n",
    "bhat = slope(df['parent'], df['child'])\n",
    "\n",
    "print(\"predicted y = {} + {} * average parent's height\".format(np.round(ahat, 2), np.round(bhat, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what our linear model looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x = df['parent'], y = df['child'], mode = 'markers', name = 'actual'))\n",
    "fig.add_trace(go.Scatter(x = df['parent'], y = df['child_predicted'], mode = 'markers', name = 'predicted means', line=dict(color='gold')))\n",
    "fig.add_trace(go.Scatter(x = df['parent'], y = ahat + bhat*df['parent'], name = 'linear model', line=dict(color='red')))\n",
    "\n",
    "\n",
    "fig.update_layout(xaxis_title = 'MidParent Height', yaxis_title = 'Child Height')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Loss Surface\n",
    "\n",
    "Let's look at what the loss surface for the above model looks like. Don't worry too much about what this code is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y, yhat):\n",
    "    return np.mean((y - yhat)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes in our choice of [a, b] as a list, and returns\n",
    "# the MSE for the corresponding linear model\n",
    "def mse_for_height_model(t):\n",
    "    a, b = t\n",
    "    return mse(df['child'], a + b*df['parent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 200 # increase for better resolution, but it will run more slowly. \n",
    "\n",
    "# if (num_points <= 100):\n",
    "\n",
    "uvalues = np.linspace(20, 32, num_points)\n",
    "vvalues = np.linspace(-1, 3, num_points)\n",
    "(u,v) = np.meshgrid(uvalues, vvalues)\n",
    "thetas = np.vstack((u.flatten(),v.flatten()))\n",
    "\n",
    "MSE = np.array([mse_for_height_model(t) for t in thetas.T])\n",
    "\n",
    "loss_surface = go.Surface(x=u, y=v, z=np.reshape(MSE, u.shape))\n",
    "\n",
    "opt_point = go.Scatter3d(x = [ahat], y = [bhat], z = [mse_for_height_model((ahat, bhat))],\n",
    "            mode = 'markers', name = 'optimal parameters',\n",
    "            marker=dict(size=10, color='gold'))\n",
    "\n",
    "fig = go.Figure(data=[loss_surface])\n",
    "fig.add_trace(opt_point)\n",
    "\n",
    "fig.update_layout(scene = dict(\n",
    "    xaxis_title = \"theta0\",\n",
    "    yaxis_title = \"theta1\",\n",
    "    zaxis_title = \"MSE\"))\n",
    "\n",
    "\n",
    "fig.show()\n",
    "# else:\n",
    "#     print(\"Picking num points > 100 can be really slow. If you really want to try, edit the code above so that this if statement doesn't trigger.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our choice of $\\hat{a}, \\hat{b}$ truly do minimize mean squared error. They exist at the minimum value of the loss surface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in a new dataset. This is aggregate per-player data from the 2018-19 NBA season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba = pd.read_csv('nba18-19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's suppose our goal is to predict the number of points someone averaged (`PTS`; this is our dependent variable). The independent variables we'll use are\n",
    "- `AST`, the average number of assists per game, and\n",
    "- `3PA`, the number of 3 point field goals attempted per game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba[['AST', '3PA', 'PTS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's explore and fit a model using just `AST`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(nba['AST'], nba['PTS'])\n",
    "plt.xlabel('average assists per game')\n",
    "plt.ylabel('average points per game');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_nba = correlation(nba['AST'], nba['PTS'])\n",
    "r_nba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation between `AST` and `PTS` is relativelty strong. However, the scatter plot above tells us this isn't exactly the optimal setting in which to perform linear regression. For the purposes of illustration, we'll continue with it anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahat_nba = intercept(nba['AST'], nba['PTS'])\n",
    "bhat_nba = slope(nba['AST'], nba['PTS'])\n",
    "\n",
    "print(\"predicted PTS = {} + {} * AST\".format(np.round(ahat_nba, 2), np.round(bhat_nba, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ast_only = ahat_nba + bhat_nba*nba['AST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x = nba['AST'], y = nba['PTS'], mode = 'markers', name = 'actual'))\n",
    "fig.add_trace(go.Scatter(x = nba['AST'], y = pred_ast_only, name = 'predictions', line=dict(color='red')))\n",
    "\n",
    "\n",
    "fig.update_layout(xaxis_title = 'AST', yaxis_title = 'PTS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model does _okay_. Let's compute the RMSE (that is, the square root of the mean squared error; we take the square root so that the RMSE is in the same units as our $y$ values). We will use this as a baseline for when we add more indepedent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, yhat):\n",
    "    return mse(y, yhat)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_ast_only = rmse(nba['PTS'], pred_ast_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_ast_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's still a ton of variation in our model. Let's see if we can do better, by incorporating `3PA` as well (that is, the average number of 3 point shot attempts they made per game).\n",
    "\n",
    "Specifically, we're looking to create the model\n",
    "\n",
    "$$\\text{predicted PTS} = \\theta_0 + \\theta_1 \\cdot \\text{AST} + \\theta_2 \\cdot \\text{3PA}$$\n",
    "\n",
    "In orrder to do this, we're going to import a new library, called `sklearn`. Don't worry too much about what it's doing for now â€“ we will dedicate an entire section of lecture to it in 2 lectures from now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm.LinearRegression(fit_intercept = True)\n",
    "\n",
    "model.fit(nba[['AST', '3PA']], nba['PTS']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above outputs tell us that the parameters that minimize MSE for this model are\n",
    "- $\\theta_0 = 2.1563$\n",
    "- $\\theta_1 = 1.6407$\n",
    "- $\\theta_2 = 1.2576$\n",
    "\n",
    "Meaning our predictions should be of the form\n",
    "\n",
    "$$\\text{predicted PTS} = 2.1563 + 1.6407 \\cdot \\text{AST} + 1.2576 \\cdot \\text{3PA}$$\n",
    "\n",
    "Let's visualize what our model and predictions look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ast_3pa = model.predict(nba[['AST', '3PA']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "nba_data_raw = go.Scatter3d(x = nba['AST'], y = nba['3PA'], z = nba['PTS'],\n",
    "            mode = 'markers', marker=dict(color='cornflowerblue', size = 5), name = 'actual')\n",
    "\n",
    "num_points = 100\n",
    "xvalues = np.linspace(0, 11, num_points)\n",
    "yvalues = np.linspace(0, 10, num_points)\n",
    "(u,v) = np.meshgrid(xvalues, yvalues)\n",
    "ast3pa = np.vstack((u.flatten(),v.flatten()))\n",
    "\n",
    "pred_pts = np.array([model.predict(coord.reshape(1, -1)) for coord in ast3pa.T])\n",
    "\n",
    "loss_surface = go.Surface(x=u, y=v, z=np.reshape(pred_pts, u.shape), name = 'predicted')\n",
    "\n",
    "# prediction_surface = go.Scatter3d(x = nba['AST'], y = nba['3PA'], z = pred_ast_3pa, line = dict(color='gold'),\n",
    "#                                  mode = 'markers')\n",
    "\n",
    "fig.add_trace(loss_surface)\n",
    "fig.add_trace(nba_data_raw)\n",
    "\n",
    "fig.update_layout(scene = dict(\n",
    "    xaxis_title = \"AST\",\n",
    "    yaxis_title = \"3PA\",\n",
    "    zaxis_title = \"PTS\"))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of our model being a line, it is now a plane in 3D (the colorful surface above). The blue points above are the true `PTS` values.\n",
    "\n",
    "It's sometimes hard to interpret things in 3D; we can also visualize in 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x = nba['AST'], y = nba['PTS'], mode = 'markers', name = 'actual'))\n",
    "fig.add_trace(go.Scatter(x = nba['AST'], y = pred_ast_only, name = 'lm AST only', line=dict(color='red')))\n",
    "fig.add_trace(go.Scatter(x = nba['AST'], y = pred_ast_3pa, mode = 'markers', name = 'lm AST 3PA', line=dict(color='gold')))\n",
    "\n",
    "\n",
    "fig.update_layout(xaxis_title = 'average assists per game', yaxis_title = 'points per game')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The yellow dots are the result of our updated linear model. It doesn't look linear here, because it is not solely a function of assists per game. (It was linear in the 3D figure above.) The yellow points here all lie on the colorful plane above.\n",
    "\n",
    "We can also scatter our predicted values vs. our actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x = nba['PTS'], y = pred_ast_only, mode = 'markers', name = 'lm AST only', line=dict(color='red')))\n",
    "fig.add_trace(go.Scatter(x = nba['PTS'], y = pred_ast_3pa, mode = 'markers', name = 'lm AST 3PA', line=dict(color='gold')))\n",
    "\n",
    "\n",
    "fig.update_layout(xaxis_title = 'actual points per game', yaxis_title = 'predicted points per game')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also look at our RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ast_3pa = model.predict(nba[['AST', '3PA']])\n",
    "\n",
    "rmse_ast_3pa = rmse(nba['PTS'], pred_ast_3pa)\n",
    "rmse_ast_3pa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's noticably lower than before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_ast_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_ast_only = np.var(pred_ast_only) / np.var(nba['PTS'])\n",
    "r2_ast_3pa = np.var(pred_ast_3pa) / np.var(nba['PTS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_ast_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(pred_ast_only, nba['PTS'])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_ast_3pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(pred_ast_3pa, nba['PTS'])**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that our model that only uses `AST` can explain 45% of the variation of the true observations (`PTS` values), while our model that uses `AST` and `3PA` can explain 60% of the variation. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
